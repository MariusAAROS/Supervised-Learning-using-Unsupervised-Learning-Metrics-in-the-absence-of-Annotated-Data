{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\myLibraries\")\n",
    "from MARScore.utils import *\n",
    "from MARScore.score import MARSCore\n",
    "\n",
    "from custom_score.utils import cleanString\n",
    "from sklearn.cluster import SpectralClustering, Birch\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(r'C:\\Pro\\Stages\\A4 - DVRC\\Work\\Datasets\\pubmed\\test.json', lines=True)\n",
    "dataset = dataset[[\"article_text\", \"abstract_text\"]]\n",
    "cleaner = lambda x: \". \".join(x).replace(\"<S>\", \"\").strip()\n",
    "format_dot = lambda x: x.replace(\" .\", \".\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleaner)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleaner)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleanString)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleanString)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(format_dot)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(format_dot)\n",
    "dataset = dataset.rename(columns={\"abstract_text\": \"summary\",\n",
    "                        \"article_text\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dataset.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus to Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpusToSentences(corpus):\n",
    "    corpus_sentences = []\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    for indiv in corpus:\n",
    "        doc = nlp(indiv)\n",
    "        corpus_sentences.append([sent.text for sent in doc.sents])   \n",
    "    return corpus_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = corpusToSentences(subset[\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanMarkers(embs, labels, mode=\"all\", ignore=[\".\"]):\n",
    "    \"\"\"\n",
    "    Removes vectors associated with noisy words such as stop words, punctuation, and BERT separator tokens.\n",
    "\n",
    "    :param1 embs (list): List of words embeddings.\n",
    "    :param2 labels (list): List of text token associated with each embedding.\n",
    "\n",
    "    :output1 new_embs (list): Cleansed list of words embeddings.\n",
    "    :output2 new_labels (list): Cleansed list of tokens.\n",
    "    :output3 -1 (int): Error output.\n",
    "    \"\"\"\n",
    "    token_indexes = [i for i in range(len(labels)) if (labels[i] != \"[PAD]\" and labels[i] != \"[CLS]\" and labels[i] != \"[SEP]\") or labels[i] in ignore]\n",
    "    new_embs = [embs[i] for i in range(len(embs)) if i in token_indexes]\n",
    "    new_labels = [labels[i] for i in range(len(labels)) if i in token_indexes]\n",
    "\n",
    "    if mode == \"all\":\n",
    "        return new_embs, new_labels\n",
    "    elif mode == \"emb\":\n",
    "        return new_embs\n",
    "    elif mode == \"lab\":\n",
    "        return new_labels\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o, l = tokenizeCorpus(subset[\"text\"][0])\n",
    "v = vectorizeCorpus(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, l = cleanMarkers(v, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \".join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenced_tokens = corpusToSentences([\" \".join(l)])\n",
    "print(sentenced_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = [i for i, sent in enumerate(sentenced_tokens[0]) for _ in sent.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences clusters visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MARSCore(subset[\"text\"].to_list(),\n",
    "              subset[\"summary\"].to_list(),\n",
    "              precision_level=\"s\",\n",
    "              ratio=5,\n",
    "              n_allowed_elements=7,\n",
    "              extraction_method=\"concat_l4\",\n",
    "              model=BertModel.from_pretrained('aitslab/biobert_huner_gene_v1'),\n",
    "              tokenizer=BertTokenizer.from_pretrained('aitslab/biobert_huner_gene_v1'))\n",
    "              #clusterizer=AffinityPropagation(random_state=0))\n",
    "ms.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_map(ms, index):\n",
    "    sentences_mask = [i for i, sent in enumerate(ms.sentenced_labels[index]) for _ in sent.split(\" \")]\n",
    "    sentences_map = {0: []}\n",
    "    for cluster_index, smask in zip(ms.clusters_labels[index], sentences_mask):\n",
    "        if cluster_index in sentences_map.keys():\n",
    "            sentences_map[cluster_index].append(smask)\n",
    "        else:\n",
    "            sentences_map[cluster_index] = [smask]\n",
    "    inv_smap = {}\n",
    "    for k,v in sentences_map.items():\n",
    "        for x in v:\n",
    "            if x in inv_smap.keys():\n",
    "                inv_smap[x].add(k)\n",
    "            else:\n",
    "                inv_smap[x] = set([k])\n",
    "    inv_smap = {k: list(v) for k, v in inv_smap.items()}\n",
    "    return inv_smap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smap = sentences_map(ms, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{35: [0, 2, 69, 5, 8, 12, 13, 14, 49, 115, 19, -1],\n",
       " 36: [0, 33, 2, 3, 1, 38, 8, 41, 75, 76, 13, 12, 79, 115, 19, -1],\n",
       " 40: [0, 33, 2, 3, 1, 100, 70, 39, 41, 9, 12, 13, 46, 22, 55, 122, 92, -1],\n",
       " 44: [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  9,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  20,\n",
       "  32,\n",
       "  33,\n",
       "  41,\n",
       "  45,\n",
       "  49,\n",
       "  68,\n",
       "  74,\n",
       "  76,\n",
       "  78,\n",
       "  79,\n",
       "  95,\n",
       "  96,\n",
       "  99,\n",
       "  102,\n",
       "  107,\n",
       "  115,\n",
       "  -1],\n",
       " 46: [0,\n",
       "  3,\n",
       "  6,\n",
       "  9,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  16,\n",
       "  17,\n",
       "  20,\n",
       "  33,\n",
       "  41,\n",
       "  44,\n",
       "  46,\n",
       "  52,\n",
       "  54,\n",
       "  60,\n",
       "  65,\n",
       "  67,\n",
       "  68,\n",
       "  70,\n",
       "  77,\n",
       "  78,\n",
       "  89,\n",
       "  90,\n",
       "  92,\n",
       "  94,\n",
       "  96,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  112,\n",
       "  -1],\n",
       " 0: [33, 34, 35, 25, 26, 60, -1],\n",
       " 1: [35, 10, 18, 118, 25, 60, -1, 63],\n",
       " 3: [41, 106, 76, 18, 53, 54, 87, 62, -1],\n",
       " 4: [2, 3, 81, 83, 20, 84, 27, 28, -1],\n",
       " 5: [130, 3, 106, 76, 77, 117, -1, 57, 62],\n",
       " 6: [130, 37, 108, 111, 82, 117, -1, 62],\n",
       " 7: [117, 42, 53, -1],\n",
       " 8: [41, 106, 76, 108, 117, 57, -1],\n",
       " 9: [129, 130, 72, 108, 77, 14, 111, 83, 118, -1, 57, 58, 27, 28, 62],\n",
       " 10: [130, 6, 73, 106, 14, 46, 16, 119, 118, -1, 57, 60, 62],\n",
       " 11: [33, 106, 28, 14, 81, 20, 84, 118, 119, 27, 60, -1],\n",
       " 12: [129,\n",
       "  1,\n",
       "  131,\n",
       "  6,\n",
       "  17,\n",
       "  23,\n",
       "  27,\n",
       "  28,\n",
       "  33,\n",
       "  37,\n",
       "  41,\n",
       "  44,\n",
       "  53,\n",
       "  59,\n",
       "  61,\n",
       "  62,\n",
       "  68,\n",
       "  73,\n",
       "  74,\n",
       "  76,\n",
       "  81,\n",
       "  82,\n",
       "  84,\n",
       "  89,\n",
       "  90,\n",
       "  94,\n",
       "  104,\n",
       "  106,\n",
       "  111,\n",
       "  112,\n",
       "  117,\n",
       "  118,\n",
       "  126,\n",
       "  124,\n",
       "  -1],\n",
       " 15: [128,\n",
       "  6,\n",
       "  11,\n",
       "  16,\n",
       "  23,\n",
       "  32,\n",
       "  33,\n",
       "  41,\n",
       "  44,\n",
       "  46,\n",
       "  59,\n",
       "  66,\n",
       "  70,\n",
       "  73,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  96,\n",
       "  107,\n",
       "  -1,\n",
       "  119,\n",
       "  121,\n",
       "  126],\n",
       " 16: [129,\n",
       "  130,\n",
       "  132,\n",
       "  6,\n",
       "  16,\n",
       "  17,\n",
       "  33,\n",
       "  37,\n",
       "  41,\n",
       "  44,\n",
       "  52,\n",
       "  68,\n",
       "  74,\n",
       "  76,\n",
       "  77,\n",
       "  82,\n",
       "  93,\n",
       "  115,\n",
       "  116,\n",
       "  124,\n",
       "  -1],\n",
       " 17: [129,\n",
       "  32,\n",
       "  33,\n",
       "  39,\n",
       "  41,\n",
       "  44,\n",
       "  45,\n",
       "  47,\n",
       "  49,\n",
       "  50,\n",
       "  52,\n",
       "  54,\n",
       "  56,\n",
       "  68,\n",
       "  86,\n",
       "  91,\n",
       "  94,\n",
       "  115,\n",
       "  -1,\n",
       "  122,\n",
       "  124,\n",
       "  126],\n",
       " 18: [32, 100, 101, 71, 41, 74, 75, 44, 48, 115, 52, 53, -1],\n",
       " 19: [6, 16, 48, 115, -1, 122, 27, 94],\n",
       " 20: [8,\n",
       "  17,\n",
       "  19,\n",
       "  22,\n",
       "  33,\n",
       "  38,\n",
       "  41,\n",
       "  44,\n",
       "  49,\n",
       "  50,\n",
       "  54,\n",
       "  59,\n",
       "  69,\n",
       "  74,\n",
       "  76,\n",
       "  92,\n",
       "  96,\n",
       "  101,\n",
       "  115,\n",
       "  122,\n",
       "  -1],\n",
       " 21: [1,\n",
       "  6,\n",
       "  8,\n",
       "  16,\n",
       "  17,\n",
       "  19,\n",
       "  33,\n",
       "  37,\n",
       "  38,\n",
       "  44,\n",
       "  45,\n",
       "  47,\n",
       "  52,\n",
       "  75,\n",
       "  82,\n",
       "  86,\n",
       "  94,\n",
       "  109,\n",
       "  113,\n",
       "  115,\n",
       "  -1],\n",
       " 22: [32, 68, 41, 115, 52, 93, -1],\n",
       " 23: [32, 69, 8, 41, 75, 45, 47, 112, 17, 15, 115, 19, 54, -1, 89, 124, 126],\n",
       " 24: [1,\n",
       "  6,\n",
       "  8,\n",
       "  9,\n",
       "  15,\n",
       "  16,\n",
       "  19,\n",
       "  22,\n",
       "  40,\n",
       "  41,\n",
       "  44,\n",
       "  46,\n",
       "  52,\n",
       "  54,\n",
       "  60,\n",
       "  69,\n",
       "  78,\n",
       "  109,\n",
       "  113,\n",
       "  115,\n",
       "  -1],\n",
       " 25: [128,\n",
       "  5,\n",
       "  14,\n",
       "  19,\n",
       "  24,\n",
       "  29,\n",
       "  32,\n",
       "  33,\n",
       "  40,\n",
       "  41,\n",
       "  45,\n",
       "  47,\n",
       "  49,\n",
       "  50,\n",
       "  52,\n",
       "  54,\n",
       "  56,\n",
       "  61,\n",
       "  68,\n",
       "  69,\n",
       "  92,\n",
       "  101,\n",
       "  112,\n",
       "  114,\n",
       "  115,\n",
       "  -1],\n",
       " 26: [33, 2, 3, 5, 39, 107, 14, 47, 29, 19, 54, 90, 61, -1],\n",
       " 28: [5,\n",
       "  6,\n",
       "  11,\n",
       "  22,\n",
       "  24,\n",
       "  33,\n",
       "  54,\n",
       "  61,\n",
       "  67,\n",
       "  69,\n",
       "  70,\n",
       "  90,\n",
       "  92,\n",
       "  99,\n",
       "  100,\n",
       "  112,\n",
       "  114,\n",
       "  115,\n",
       "  -1],\n",
       " 29: [99, 69, 5, 47, 112, 114, 115, 20, 54, 22, 24, 90, 92, -1],\n",
       " 30: [33, 1, 68, 37, 6, 70, 71, 69, 78, 48, 115, 53, 54, 24, 92, 61, -1],\n",
       " 32: [32, 33, 1, 69, 102, 41, 75, 78, 79, 112, 113, 115, 116, -1, 24, 91, 94],\n",
       " 33: [96, 33, 1, 65, 68, 69, 38, 41, 9, 17, 54, 55, 89, -1],\n",
       " 34: [33, 2, 1, 65, 69, 39, 8, 41, 9, 12, 13, 46, 19, 54, -1],\n",
       " 38: [1, 3, 67, 70, 39, 41, 74, 9, 12, 46, 55, 92, 29, -1],\n",
       " 39: [96, 65, 97, 67, 70, 54, -1],\n",
       " 41: [1, 2, 99, 101, 12, 13, 78, 90, 92, 61, -1],\n",
       " 42: [96, 33, 1, 3, 99, 65, 73, 9, 55, -1],\n",
       " 43: [33, 2, 1, 99, 97, 41, 9, 12, 77, 46, 55, 90, 92, -1],\n",
       " 47: [6,\n",
       "  11,\n",
       "  16,\n",
       "  17,\n",
       "  23,\n",
       "  33,\n",
       "  41,\n",
       "  44,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  73,\n",
       "  76,\n",
       "  90,\n",
       "  104,\n",
       "  106,\n",
       "  115,\n",
       "  121,\n",
       "  125,\n",
       "  -1],\n",
       " 48: [33, 66, 67, 70, 11, 78, 112, 23, 121, 90, 92, 29, -1],\n",
       " 49: [33, 65, 99, 100, 6, 76, 44, 46, 16, 112, 52, 54, 90, 92, 61, -1],\n",
       " 50: [32, 128, 73, 107, 17, 51, -1, 87, 89, 90, 126],\n",
       " 51: [128, 33, 37, 40, 41, 43, 11, 77, 48, 23, 121, 90, -1],\n",
       " 52: [129,\n",
       "  122,\n",
       "  71,\n",
       "  104,\n",
       "  73,\n",
       "  41,\n",
       "  103,\n",
       "  108,\n",
       "  48,\n",
       "  17,\n",
       "  49,\n",
       "  116,\n",
       "  126,\n",
       "  59,\n",
       "  93,\n",
       "  -1,\n",
       "  127],\n",
       " 53: [33, 116, 122, 123, -1, 127],\n",
       " 54: [33, 123, 116, 24, 122, 27, -1, 127],\n",
       " 55: [128, 33, 104, 41, 123, 116, 89, 122, 27, 28, -1, 127],\n",
       " 56: [33,\n",
       "  129,\n",
       "  90,\n",
       "  122,\n",
       "  104,\n",
       "  73,\n",
       "  41,\n",
       "  48,\n",
       "  23,\n",
       "  88,\n",
       "  89,\n",
       "  126,\n",
       "  123,\n",
       "  124,\n",
       "  93,\n",
       "  -1,\n",
       "  127],\n",
       " 57: [128, 33, 121, 98, 36, 122, 104, 11, 23, 88, 89, 90, 123, -1, 127],\n",
       " 58: [128, 98, 38, 41, 76, 44, 46, 47, 17, 87, 89, 61, -1],\n",
       " 59: [128,\n",
       "  6,\n",
       "  11,\n",
       "  16,\n",
       "  23,\n",
       "  32,\n",
       "  33,\n",
       "  37,\n",
       "  41,\n",
       "  44,\n",
       "  68,\n",
       "  73,\n",
       "  74,\n",
       "  88,\n",
       "  90,\n",
       "  106,\n",
       "  116,\n",
       "  -1,\n",
       "  119,\n",
       "  122,\n",
       "  123,\n",
       "  125,\n",
       "  126,\n",
       "  127],\n",
       " 60: [128, 98, 104, 11, 21, 30, 89, 122, 123, -1, 31],\n",
       " 61: [7, 40, 21, 26, -1, 31],\n",
       " 62: [7, 108, 80, 118, 120, -1],\n",
       " 64: [97, 130, 4, 7, 41, 106, 105, 80, 118, 119, 62, 60, -1],\n",
       " 66: [130, 108, 109, 110, 111, 117, -1, 120, 62],\n",
       " 67: [64,\n",
       "  129,\n",
       "  103,\n",
       "  72,\n",
       "  73,\n",
       "  108,\n",
       "  46,\n",
       "  111,\n",
       "  110,\n",
       "  117,\n",
       "  118,\n",
       "  53,\n",
       "  -1,\n",
       "  57,\n",
       "  58,\n",
       "  120,\n",
       "  62],\n",
       " 68: [130, 103, 72, 41, 104, 76, 80, 53, 118, 119, 62, 57, 85, 124, -1, 127],\n",
       " 69: [64, 65, 72, 76, 14, 80, -1, 57, 60, 62],\n",
       " 71: [41, 106, 73, 105, 77, 14, 46, 83, 117, 126, 125, -1],\n",
       " 72: [128,\n",
       "  6,\n",
       "  14,\n",
       "  16,\n",
       "  17,\n",
       "  44,\n",
       "  46,\n",
       "  47,\n",
       "  51,\n",
       "  52,\n",
       "  60,\n",
       "  65,\n",
       "  68,\n",
       "  74,\n",
       "  80,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  94,\n",
       "  96,\n",
       "  100,\n",
       "  106,\n",
       "  119,\n",
       "  -1],\n",
       " 73: [6,\n",
       "  11,\n",
       "  14,\n",
       "  16,\n",
       "  23,\n",
       "  41,\n",
       "  46,\n",
       "  51,\n",
       "  52,\n",
       "  65,\n",
       "  77,\n",
       "  88,\n",
       "  90,\n",
       "  93,\n",
       "  96,\n",
       "  119,\n",
       "  121,\n",
       "  124,\n",
       "  -1],\n",
       " 74: [129,\n",
       "  132,\n",
       "  8,\n",
       "  14,\n",
       "  19,\n",
       "  37,\n",
       "  41,\n",
       "  51,\n",
       "  52,\n",
       "  56,\n",
       "  73,\n",
       "  74,\n",
       "  77,\n",
       "  89,\n",
       "  93,\n",
       "  -1,\n",
       "  120,\n",
       "  124,\n",
       "  126],\n",
       " 75: [32, 65, 98, 132, 37, 41, 74, 76, 17, 82, 116, 86, 89, -1],\n",
       " 76: [32, 68, 37, 132, 36, 104, 41, 40, 76, 17, 82, 113, 52, 51, -1],\n",
       " 77: [131,\n",
       "  132,\n",
       "  32,\n",
       "  36,\n",
       "  37,\n",
       "  41,\n",
       "  45,\n",
       "  47,\n",
       "  48,\n",
       "  53,\n",
       "  56,\n",
       "  68,\n",
       "  71,\n",
       "  76,\n",
       "  78,\n",
       "  82,\n",
       "  86,\n",
       "  91,\n",
       "  94,\n",
       "  109,\n",
       "  110,\n",
       "  120,\n",
       "  124,\n",
       "  -1],\n",
       " 78: [32, 68, 37, 132, 71, 104, 41, 74, 45, 79, 17, 50, 49, 52, 94, -1, 95],\n",
       " 79: [1, 37, 6, 71, 41, 91, 45, 46, 109, 110, 20, 120, 94, 27, 28, -1, 63],\n",
       " 80: [33, 49, 17, 27, -1],\n",
       " 81: [132,\n",
       "  8,\n",
       "  17,\n",
       "  19,\n",
       "  33,\n",
       "  38,\n",
       "  41,\n",
       "  46,\n",
       "  50,\n",
       "  68,\n",
       "  73,\n",
       "  78,\n",
       "  92,\n",
       "  95,\n",
       "  97,\n",
       "  102,\n",
       "  104,\n",
       "  112,\n",
       "  124,\n",
       "  -1],\n",
       " 82: [32, 1, 96, 65, 36, 38, 73, 41, 9, 77, 46, 45, 113, 55, 56, -1, 95],\n",
       " 83: [36, 38, 8, 41, 112, 17, 19, 94, 54, -1, 22, 89, 125, 126, 63],\n",
       " 84: [129, 68, 37, 38, 132, 41, 77, 82, 56, 94, 124, 93, -1],\n",
       " 85: [32, 132, 37, 36, 40, 110, 17, 82, 113, 51, 120, 124, 93, -1, 63],\n",
       " 86: [68, 37, 38, 41, 77, 17, 82, 119, 88, -1],\n",
       " 87: [32,\n",
       "  131,\n",
       "  132,\n",
       "  37,\n",
       "  38,\n",
       "  36,\n",
       "  104,\n",
       "  41,\n",
       "  106,\n",
       "  107,\n",
       "  76,\n",
       "  17,\n",
       "  94,\n",
       "  85,\n",
       "  87,\n",
       "  89,\n",
       "  61,\n",
       "  -1],\n",
       " 88: [33,\n",
       "  121,\n",
       "  66,\n",
       "  70,\n",
       "  104,\n",
       "  41,\n",
       "  74,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  17,\n",
       "  85,\n",
       "  -1,\n",
       "  23,\n",
       "  120,\n",
       "  89,\n",
       "  93,\n",
       "  126],\n",
       " 89: [36, 41, 17, 85, -1],\n",
       " 13: [33, 6, 38, 73, 41, 43, 77, 16, 17, 125, 93, 63],\n",
       " 45: [128, 33, 5, 38, 77, 14, 20],\n",
       " 2: [18],\n",
       " 63: [7, 103, 77, 80, 118, 62],\n",
       " 31: [41, 91, 70],\n",
       " 37: [96, 1, 2, 65, 36, 97, 102, 39, 41, 9, 77, 13, 20, 54, 55, 95],\n",
       " 14: [90, 107, 87],\n",
       " 27: [66, 67, 69, 70, 112, 114, 115, 20, 29, 54, 23, 121, 92, 61],\n",
       " 70: [83, 27],\n",
       " 65: [130]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selector(ms, s_map, index):\n",
    "    selectedClusters = []\n",
    "    for sel_index in ms.selectedIndexes[index]:\n",
    "        selectedClusters.extend(s_map[sel_index])\n",
    "    return list(set(selectedClusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "101",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m selectedClusters \u001b[39m=\u001b[39m selector(ms, smap, \u001b[39m0\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m, in \u001b[0;36mselector\u001b[1;34m(ms, s_map, index)\u001b[0m\n\u001b[0;32m      2\u001b[0m selectedClusters \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m sel_index \u001b[39min\u001b[39;00m ms\u001b[39m.\u001b[39mselectedIndexes[index]:\n\u001b[1;32m----> 4\u001b[0m     selectedClusters\u001b[39m.\u001b[39mextend(s_map[sel_index])\n\u001b[0;32m      5\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(selectedClusters))\n",
      "\u001b[1;31mKeyError\u001b[0m: 101"
     ]
    }
   ],
   "source": [
    "selectedClusters = selector(ms, smap, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_viz(reductor, embs, labels, selected_clusters, embs_gold=None, labels_gold=None, labels_cluster=None, tf_values=None,):\n",
    "    \n",
    "    def colorize(label=None, glabels=[], clabel=None, cmap=[], mode=\"unclustered\"):\n",
    "        \"\"\"\n",
    "        Colorize vector's projections depending on the context. \n",
    "\n",
    "        :param1 label (string): Single Token.\n",
    "        :param2 glabel (list): List of gold tokens.\n",
    "        :param3 clabel (int): Cluster's index of the current token.\n",
    "        :param4 cmap (color_map): Matplotlib color map.\n",
    "        :param5 mode (string): Equals to <clustered>, <unclustered> to respectively colorize depending on gold's, cluster's belonging.\n",
    "\n",
    "        :output color (string): CSS text color.  \n",
    "        \"\"\"\n",
    "        comp_gold = True if label != None and glabels != [] else False\n",
    "        assert label != None or glabels != [] or clabel != None, \"ERROR: No labels detected\"\n",
    "        if mode == \"unclustered\":\n",
    "            if comp_gold:\n",
    "                color = \"green\" if label in glabels else 'red'\n",
    "            else:\n",
    "                color = \"red\"\n",
    "        elif mode == \"clustered\":\n",
    "            if clabel != None and cmap != []:\n",
    "                color = cmap[clabel]\n",
    "            else:\n",
    "                color = \"black\"\n",
    "        return color\n",
    "    \n",
    "    cmap = colormaps[\"viridis\"].colors\n",
    "    formated_embs = np.array(embs)\n",
    "    formated_embs_gold = np.array(embs_gold)\n",
    "    token_indexes = [i for i in range(len(labels)) if labels[i] != \"[PAD]\" and labels[i] != \"[CLS]\" and labels[i] != \"[SEP]\"]\n",
    "\n",
    "    proj2D = np.transpose(embs)\n",
    "    data = {\"x\": proj2D[0],\n",
    "            \"y\": proj2D[1],\n",
    "            \"labels\": labels,\n",
    "            \"clusters\": labels_cluster}\n",
    "    for k in data.keys():\n",
    "        data[k] = [data[k][i] for i in range(len(data[k])) if i in token_indexes]\n",
    "\n",
    "    token_indexes_gold = [i for i in range(len(labels_gold)) if labels_gold[i] != \"[PAD]\" and labels_gold[i] != \"[CLS]\" and labels_gold[i] != \"[SEP]\"]\n",
    "    proj2D_gold = reductor.transform(formated_embs_gold).T\n",
    "    data_gold = {\"x\": proj2D_gold[0],\n",
    "                 \"y\": proj2D_gold[1],\n",
    "                 \"labels\": labels_gold}\n",
    "    for k in data_gold.keys():\n",
    "        data_gold[k] = [data_gold[k][i] for i in range(len(data_gold[k])) if i in token_indexes_gold]\n",
    "\n",
    "    traces = []\n",
    "    for i in range(len(data['x'])):\n",
    "        if labels_cluster[i] in selected_clusters:\n",
    "            if data[\"clusters\"] != None:\n",
    "                color = colorize(clabel=data[\"clusters\"][i], cmap=cmap, mode=\"clustered\")\n",
    "            else:\n",
    "                color = colorize(labels=data['labels'][i], glabels=data_gold['labels'], mode=\"unclustered\")\n",
    "            trace = go.Scatter(\n",
    "                x=[data['x'][i]],\n",
    "                y=[data['y'][i]],\n",
    "                mode='markers',\n",
    "                marker=dict(size=9, color=color),\n",
    "                line=dict(width=2, color=\"DarkSlateGrey\"),\n",
    "                text=[\"token: \"+str(data['labels'][i]) +\" || \"+\"tf   : \"+str(tf_values[data['labels'][i]])+\" || cluster: \"+str(data[\"clusters\"][i])],\n",
    "                name=data['labels'][i]\n",
    "            )\n",
    "            traces.append(trace)\n",
    "    \n",
    "    for i in range(len(data_gold['x'])):\n",
    "        trace = go.Scatter(\n",
    "            x=[data_gold['x'][i]],\n",
    "            y=[data_gold['y'][i]],\n",
    "            mode='markers',\n",
    "            marker=dict(size=9, color='red'),\n",
    "            marker_symbol=\"diamond\",\n",
    "            line=dict(width=2, color=\"DarkSlateGrey\"),\n",
    "            text=[\"token: \"+str(data_gold['labels'][i])],\n",
    "            name=data_gold['labels'][i]\n",
    "        )\n",
    "        traces.append(trace) \n",
    "    layout = go.Layout(\n",
    "    title='2D Scatter Plot',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='X'),\n",
    "        yaxis=dict(title='Y')\n",
    "    ),\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=1000\n",
    "    )\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    fig.update_yaxes(\n",
    "        scaleanchor=\"x\",\n",
    "        scaleratio=1,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_gold, l_gold = tokenizeCorpus(ms.gold[0])\n",
    "v_gold = vectorizeCorpus(o_gold, method=ms.extraction_method)\n",
    "v_gold, l_gold = cleanAll(v_gold, l_gold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_viz(ms.dim_reductor, ms.vectors[0], ms.labels[0], selectedClusters, v_gold, l_gold, ms.clusters_labels[0], ms.tokens_tfs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
