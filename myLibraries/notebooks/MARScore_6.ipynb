{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\myLibraries\")\n",
    "from MARScore.score import MARSCore\n",
    "from custom_score.utils import cleanString\n",
    "from datasets_loaders.loaders import load_billsum\n",
    "from sklearn.cluster import SpectralClustering, Birch\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(r'C:\\Pro\\Stages\\A4 - DVRC\\Work\\Datasets\\pubmed\\test.json', lines=True)\n",
    "dataset = dataset[[\"article_text\", \"abstract_text\"]]\n",
    "cleaner = lambda x: \". \".join(x).replace(\"<S>\", \"\").strip()\n",
    "format_dot = lambda x: x.replace(\" .\", \".\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleaner)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleaner)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleanString)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleanString)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(format_dot)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(format_dot)\n",
    "dataset = dataset.rename(columns={\"abstract_text\": \"summary\",\n",
    "                        \"article_text\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dataset.iloc[3:5, :]\n",
    "subset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ILP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\n",
    "    \"My left knee is higly damaged. I might not be able to run anymore. I am not happy about this news.\",\n",
    "    \"I work as a data scientist in an IT company. I love data science. I word there since 2 years.\",\n",
    "    \"My neighbord often plays guitar. My mother is a very nice person. Sometimes I accompany him on the piano.\",\n",
    "    \"Most days, I pratice sports. I run and go to the gym 5 times a week. It is complementary with intellectual activities.\"\n",
    "]\n",
    "\n",
    "golds = [\n",
    "    \"My articulation hurts.\",\n",
    "    \"I am a pasionnate engineer.\",\n",
    "    \"Music helps me connect with people.\",\n",
    "    \"Physical activities occupy a consequent part of my life.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MARSCore(sources, golds, precision_level=\"c\", ratio=2, clusterizer=Birch(), printRange=(range(3)))\n",
    "ms.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'I love data science.',\n",
       " 'My neighbord often plays guitar.',\n",
       " 'It is complementary with intellectual activities.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 1, 1, 1, 2]),\n",
       " array([0, 0, 1, 1, 1, 2, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 2]),\n",
       " array([1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 2]),\n",
       " array([0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 2])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.clusters_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _\u001b[39m=\u001b[39mms\u001b[39m.\u001b[39;49massess()\n",
      "File \u001b[1;32mC:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\myLibraries\\MARScore\\score.py:191\u001b[0m, in \u001b[0;36mMARSCore.assess\u001b[1;34m(self, start, stop, verbose)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39m#BERTScore computation\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mwith\u001b[39;00m nostd():\n\u001b[1;32m--> 191\u001b[0m     bertscore \u001b[39m=\u001b[39m bert_score\u001b[39m.\u001b[39;49mscore(subset_summaries, subset_gold, lang\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m\"\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    192\u001b[0m \u001b[39m#bartscore\u001b[39;00m\n\u001b[0;32m    193\u001b[0m bart_scorer \u001b[39m=\u001b[39m BARTScorer(device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m, checkpoint\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfacebook/bart-large-cnn\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\bert_score\\score.py:123\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcalculating scores...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    122\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m--> 123\u001b[0m all_preds \u001b[39m=\u001b[39m bert_cos_score_idf(\n\u001b[0;32m    124\u001b[0m     model,\n\u001b[0;32m    125\u001b[0m     refs,\n\u001b[0;32m    126\u001b[0m     cands,\n\u001b[0;32m    127\u001b[0m     tokenizer,\n\u001b[0;32m    128\u001b[0m     idf_dict,\n\u001b[0;32m    129\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    130\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m    131\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    132\u001b[0m     all_layers\u001b[39m=\u001b[39;49mall_layers,\n\u001b[0;32m    133\u001b[0m )\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m    135\u001b[0m \u001b[39mif\u001b[39;00m ref_group_boundaries \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     max_preds \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\bert_score\\utils.py:616\u001b[0m, in \u001b[0;36mbert_cos_score_idf\u001b[1;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[39mfor\u001b[39;00m batch_start \u001b[39min\u001b[39;00m iter_range:\n\u001b[0;32m    615\u001b[0m     sen_batch \u001b[39m=\u001b[39m sentences[batch_start : batch_start \u001b[39m+\u001b[39m batch_size]\n\u001b[1;32m--> 616\u001b[0m     embs, masks, padded_idf \u001b[39m=\u001b[39m get_bert_embedding(\n\u001b[0;32m    617\u001b[0m         sen_batch, model, tokenizer, idf_dict, device\u001b[39m=\u001b[39;49mdevice, all_layers\u001b[39m=\u001b[39;49mall_layers\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    619\u001b[0m     embs \u001b[39m=\u001b[39m embs\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m    620\u001b[0m     masks \u001b[39m=\u001b[39m masks\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[1;32mc:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\bert_score\\utils.py:455\u001b[0m, in \u001b[0;36mget_bert_embedding\u001b[1;34m(all_sens, model, tokenizer, idf_dict, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m    454\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(all_sens), batch_size):\n\u001b[1;32m--> 455\u001b[0m         batch_embedding \u001b[39m=\u001b[39m bert_encode(\n\u001b[0;32m    456\u001b[0m             model,\n\u001b[0;32m    457\u001b[0m             padded_sens[i : i \u001b[39m+\u001b[39;49m batch_size],\n\u001b[0;32m    458\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mmask[i : i \u001b[39m+\u001b[39;49m batch_size],\n\u001b[0;32m    459\u001b[0m             all_layers\u001b[39m=\u001b[39;49mall_layers,\n\u001b[0;32m    460\u001b[0m         )\n\u001b[0;32m    461\u001b[0m         embeddings\u001b[39m.\u001b[39mappend(batch_embedding)\n\u001b[0;32m    462\u001b[0m         \u001b[39mdel\u001b[39;00m batch_embedding\n",
      "File \u001b[1;32mc:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\bert_score\\utils.py:351\u001b[0m, in \u001b[0;36mbert_encode\u001b[1;34m(model, x, attention_mask, all_layers)\u001b[0m\n\u001b[0;32m    349\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m    350\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 351\u001b[0m     out \u001b[39m=\u001b[39m model(x, attention_mask\u001b[39m=\u001b[39;49mattention_mask, output_hidden_states\u001b[39m=\u001b[39;49mall_layers)\n\u001b[0;32m    352\u001b[0m \u001b[39mif\u001b[39;00m all_layers:\n\u001b[0;32m    353\u001b[0m     emb \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(out[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:825\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    821\u001b[0m         token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m    823\u001b[0m \u001b[39m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[39m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[1;32m--> 825\u001b[0m extended_attention_mask: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_extended_attention_mask(attention_mask, input_shape)\n\u001b[0;32m    827\u001b[0m \u001b[39m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[39m# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_decoder \u001b[39mand\u001b[39;00m encoder_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:889\u001b[0m, in \u001b[0;36mModuleUtilsMixin.get_extended_attention_mask\u001b[1;34m(self, attention_mask, input_shape, device, dtype)\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    881\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrong shape for input_ids (shape \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m) or attention_mask (shape \u001b[39m\u001b[39m{\u001b[39;00mattention_mask\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m     )\n\u001b[0;32m    884\u001b[0m \u001b[39m# Since attention_mask is 1.0 for positions we want to attend and 0.0 for\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[39m# masked positions, this operation will create a tensor which is 0.0 for\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[39m# positions we want to attend and the dtype's smallest value for masked positions.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m# Since we are adding it to the raw scores before the softmax, this is\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[39m# effectively the same as removing these entirely.\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m extended_attention_mask \u001b[39m=\u001b[39m extended_attention_mask\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdtype)  \u001b[39m# fp16 compatibility\u001b[39;00m\n\u001b[0;32m    890\u001b[0m extended_attention_mask \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m extended_attention_mask) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mfinfo(dtype)\u001b[39m.\u001b[39mmin\n\u001b[0;32m    891\u001b[0m \u001b[39mreturn\u001b[39;00m extended_attention_mask\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_=ms.assess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.visualize(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ms.cluster_distribution())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
