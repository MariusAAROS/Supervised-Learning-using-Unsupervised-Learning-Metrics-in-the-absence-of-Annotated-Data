{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select N-words with higher TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "sys.path.append(r\"C:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\myLibraries\")\n",
    "from MARScore.score import MARSCore\n",
    "from MARScore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(r'C:\\Pro\\Stages\\A4 - DVRC\\Work\\Datasets\\pubmed\\test.json', lines=True)\n",
    "dataset = dataset[[\"article_text\", \"abstract_text\"]]\n",
    "cleaner = lambda x: \". \".join(x).replace(\"<S>\", \"\").strip()\n",
    "format_dot = lambda x: x.replace(\" .\", \".\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleaner)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleaner)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleanString)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleanString)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(format_dot)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(format_dot)\n",
    "dataset = dataset.rename(columns={\"abstract_text\": \"summary\",\n",
    "                        \"article_text\": \"text\"})\n",
    "\n",
    "subset = dataset.iloc[3:5, :]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tf = []\n",
    "for indiv in subset[\"text\"].to_list():\n",
    "    o, l = tokenizeCorpus(indiv)\n",
    "    v = vectorizeCorpus(o)\n",
    "    v, l = cleanAll(v, l)\n",
    "    all_tf.append(tf(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_words_format(tfs, n):\n",
    "    output = \"Maximize\\nscore: \"\n",
    "    for i, v in enumerate(tfs.values()):\n",
    "        output += f\"+ {v} c{i}\"\n",
    "    \n",
    "    output += \"\\n\\nSubject To\\n\"\n",
    "    output += \"length:\"\n",
    "    for i, v in enumerate(tfs.values()):\n",
    "        output += f\" c{i} +\"\n",
    "    output = output[:-1]\n",
    "    output += f\"< {n}\"\n",
    "\n",
    "    output += \"\\n\\nBinary\\n\"\n",
    "    for i, v in enumerate(tfs.values()):\n",
    "        output += f\"c{i}\\n\"\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = best_words_format(all_tf[0], 4)\n",
    "\n",
    "with open(os.path.join(get_git_root(), r\"myLibraries\\ilp_outputs\\ilp_in.ilp\"), \"w\") as f:\n",
    "    f.write(format)\n",
    "    f.close()\n",
    "\n",
    "os.system(f'glpsol --tmlim 100 --lp \"{os.path.join(get_git_root(), r\"myLibraries/ilp_outputs/ilp_in.ilp\")}\" -o \"{os.path.join(get_git_root(), r\"myLibraries/ilp_outputs/ilp_out.sol\")}\"')\n",
    "\n",
    "with open(os.path.join(get_git_root(), r\"myLibraries/ilp_outputs/ilp_out.sol\"), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "sentences_lines = [line for line in lines if re.search(r\"c\\d\", line)]\n",
    "\n",
    "sorted_lines = sorted(sentences_lines, key=lambda line: int(line.split()[1][1:]))\n",
    "result = [int(sorted_line.split()[3]) for sorted_line in sorted_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i, value in enumerate(result) if value == 1]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = []\n",
    "for i, (k, v) in enumerate(all_tf[0].items()):\n",
    "    ref.append([i, k, v])\n",
    "ref.sort(key=lambda x: x[2], reverse=True)\n",
    "res = [v[0] for v in ref[:4]]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select N-sentences maximizing words tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "sys.path.append(r\"C:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\myLibraries\")\n",
    "from MARScore.score import MARSCore\n",
    "from MARScore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(r'C:\\Pro\\Stages\\A4 - DVRC\\Work\\Datasets\\pubmed\\test.json', lines=True)\n",
    "dataset = dataset[[\"article_text\", \"abstract_text\"]]\n",
    "cleaner = lambda x: \". \".join(x).replace(\"<S>\", \"\").strip()\n",
    "format_dot = lambda x: x.replace(\" .\", \".\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleaner)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleaner)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleanString)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleanString)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(format_dot)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(format_dot)\n",
    "dataset = dataset.rename(columns={\"abstract_text\": \"summary\",\n",
    "                        \"article_text\": \"text\"})\n",
    "\n",
    "subset = dataset.iloc[3:5, :]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "all_tf = []\n",
    "for indiv in subset[\"text\"].to_list():\n",
    "    o, l = tokenizeCorpus(indiv)\n",
    "    v = vectorizeCorpus(o)\n",
    "    v, l = cleanAll(v, l)\n",
    "    tfs = tf(l)\n",
    "\n",
    "    all_tokens.append(l)\n",
    "    all_tf.append(tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_sentences_format(tokens, tfs, n):\n",
    "    ### sentence tfs\n",
    "    i = 0\n",
    "    sentences_tfs = {}\n",
    "    for token in tokens:\n",
    "        if i in sentences_tfs.keys():\n",
    "            sentences_tfs[i] += tfs[token]\n",
    "        else:\n",
    "            sentences_tfs[i] = tfs[token]\n",
    "        if token == \".\":\n",
    "            i += 1\n",
    "    \n",
    "    output = \"Maximize\\nscore:\"\n",
    "    for i, cur_tf in enumerate(sentences_tfs.values()):\n",
    "        output += f\"+ {cur_tf} s{i}\"\n",
    "    \n",
    "    output += \"\\n\\nSubject To\\n\"\n",
    "    output += f\"length:\"\n",
    "    for i in range(len(sentences_tfs.keys())):\n",
    "        output += f\" s{i} +\"\n",
    "    output = output[:-1]\n",
    "    output += f\"< {n}\"\n",
    "\n",
    "    output += \"\\n\\nBinary\"\n",
    "    for i in range(len(sentences_tfs.keys())):\n",
    "        output += f\"\\ns{i}\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = best_sentences_format(all_tokens[1], all_tf[1], 4)\n",
    "\n",
    "with open(os.path.join(get_git_root(), r\"myLibraries\\ilp_outputs\\ilp_in.ilp\"), \"w\") as f:\n",
    "    f.write(format)\n",
    "    f.close()\n",
    "\n",
    "os.system(f'glpsol --tmlim 100 --lp \"{os.path.join(get_git_root(), r\"myLibraries/ilp_outputs/ilp_in.ilp\")}\" -o \"{os.path.join(get_git_root(), r\"myLibraries/ilp_outputs/ilp_out.sol\")}\"')\n",
    "\n",
    "with open(os.path.join(get_git_root(), r\"myLibraries/ilp_outputs/ilp_out.sol\"), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "sentences_lines = [line for line in lines if re.search(r\"s\\d\", line)]\n",
    "\n",
    "sorted_lines = sorted(sentences_lines, key=lambda line: int(line.split()[1][1:]))\n",
    "result = [int(sorted_line.split()[3]) for sorted_line in sorted_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i, value in enumerate(result) if value == 1]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = []\n",
    "### sentence tfs\n",
    "i = 0\n",
    "sentences_tfs = {}\n",
    "for token in all_tokens[1]:\n",
    "    if i in sentences_tfs.keys():\n",
    "        sentences_tfs[i] += all_tf[1][token]\n",
    "    else:\n",
    "        sentences_tfs[i] = all_tf[1][token]\n",
    "    if token == \".\":\n",
    "        i += 1\n",
    "\n",
    "\n",
    "for i, (k, v) in enumerate(sentences_tfs.items()):\n",
    "    ref.append([i, k, v])\n",
    "ref.sort(key=lambda x: x[2], reverse=True)\n",
    "res = [v[0] for v in ref[:4]]\n",
    "res.sort()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Hull and Inner Cluster Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "sys.path.append(r\"C:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\myLibraries\")\n",
    "from MARScore.score import MARSCore\n",
    "from MARScore.utils import *\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(r'C:\\Pro\\Stages\\A4 - DVRC\\Work\\Datasets\\pubmed\\test.json', lines=True)\n",
    "dataset = dataset[[\"article_text\", \"abstract_text\"]]\n",
    "cleaner = lambda x: \". \".join(x).replace(\"<S>\", \"\").strip()\n",
    "format_dot = lambda x: x.replace(\" .\", \".\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleaner)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleaner)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleanString)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleanString)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(format_dot)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(format_dot)\n",
    "dataset = dataset.rename(columns={\"abstract_text\": \"summary\",\n",
    "                        \"article_text\": \"text\"})\n",
    "\n",
    "subset = dataset.iloc[3:5, :]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = []\n",
    "all_reduced_embs = []\n",
    "all_tokens = []\n",
    "all_clabels = []\n",
    "for indiv in subset[\"text\"].to_list():\n",
    "    o, l = tokenizeCorpus(indiv)\n",
    "    v = vectorizeCorpus(o, method=\"concat_l4\")\n",
    "    v, l = cleanAll(v, l)\n",
    "    reduced_v, clabels = clusterizeCorpus(UMAP(n_components=2, init=\"random\", random_state=0), v, \n",
    "                                        HDBSCAN())\n",
    "    tf_values = tf(l)\n",
    "    clusters_tf_values = clusters_tf(tf_values, l, clabels)\n",
    "    all_embs.append(v)\n",
    "    all_reduced_embs.append(reduced_v)\n",
    "    all_tokens.append(l)\n",
    "    all_clabels.append(clabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_tokens(tokens, clabels, embs):\n",
    "    d = {}\n",
    "    for token, clabel, emb in zip(tokens, clabels, embs):\n",
    "        if clabel in d.keys():\n",
    "            d[clabel][\"tokens\"].append(token)\n",
    "            d[clabel][\"embs\"].append(emb)\n",
    "        else:\n",
    "            d[clabel] = {\"tokens\": [token], \"embs\": [emb]}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tokens = tidy_tokens(all_tokens[0], all_clabels[0], all_reduced_embs[0])\n",
    "for k, v in d_tokens.items():\n",
    "    d_tokens[k][\"embs\"] = np.array(v[\"embs\"])\n",
    "convex_hulls = {k: ConvexHull(v[\"embs\"]) for k, v in d_tokens.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = d_tokens[0][\"embs\"]\n",
    "hull = ConvexHull(points)\n",
    "\n",
    "# Get the indices of the points forming the convex hull\n",
    "hull_indices = hull.vertices\n",
    "hull_indices = np.append(hull_indices, hull.vertices[0])\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.plot(points[:, 0], points[:, 1], 'ko', label='Points')\n",
    "plt.plot(points[hull_indices, 0], points[hull_indices, 1], 'r-', lw=2, label='Convex Hull')\n",
    "for x, y, index in zip(points[hull_indices, 0], points[hull_indices, 1], hull_indices):\n",
    "    plt.text(x, y, str(index))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Convex Hull')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(p, q):\n",
    "    p = np.array(p)\n",
    "    q = np.array(q)\n",
    "    return np.linalg.norm(p - q)\n",
    "   \n",
    "\n",
    "def crossProduct(p, q, r):\n",
    "    pq = np.array(q) - np.array(p)\n",
    "    pr = np.array(r) - np.array(p)\n",
    "    return np.cross(pq, pr)\n",
    "    \n",
    "\n",
    "def rotatingCaliper(points, convex_hull):\n",
    "   \n",
    "    # Takes O(n)\n",
    "    hull = [points[i] for i in range(len(points)) if i in convex_hull.vertices]\n",
    "    n = len(hull)\n",
    " \n",
    "    # Base Cases\n",
    "    if n == 1:\n",
    "        return 0\n",
    "    if n == 2:\n",
    "        return euclideanDistance(hull[0], hull[1])\n",
    "    k = 1\n",
    " \n",
    "    # Find the farthest vertex\n",
    "    # from hull[0] and hull[n-1]\n",
    "    while crossProduct(hull[n - 1], hull[0], hull[(k + 1) % n]) > crossProduct(hull[n - 1], hull[0], hull[k]):\n",
    "        k += 1\n",
    " \n",
    "    res = 0\n",
    " \n",
    "    # Check points from 0 to k\n",
    "    for i in range(k + 1):\n",
    "        j = (i + 1) % n\n",
    "        while crossProduct(hull[i], hull[(i + 1) % n], hull[(j + 1) % n]) > crossProduct(hull[i], hull[(i + 1) % n], hull[j]):\n",
    "            # Update res\n",
    "            res = max(res, euclideanDistance(hull[i], hull[(j + 1) % n]))\n",
    "            j = (j + 1) % n\n",
    " \n",
    "    # Return the result distance\n",
    "    return res\n",
    "\n",
    "def biggerDistance(points):\n",
    "    points = np.array(points)\n",
    "    convex_hull = ConvexHull(points)\n",
    "    return rotatingCaliper(points, convex_hull)\n",
    "\n",
    "# Code inspired by amit_mangal_ on geeksforgeeks forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotatingCaliper(d_tokens[0][\"embs\"], convex_hulls[0]) #complexity = O(N*log(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggerDistance(d_tokens[0][\"embs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevancy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "sys.path.append(r\"C:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\myLibraries\")\n",
    "from MARScore.score import MARSCore\n",
    "from MARScore.utils import *\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json(r'C:\\Pro\\Stages\\A4 - DVRC\\Work\\Datasets\\pubmed\\test.json', lines=True)\n",
    "dataset = dataset[[\"article_text\", \"abstract_text\"]]\n",
    "cleaner = lambda x: \". \".join(x).replace(\"<S>\", \"\").strip()\n",
    "format_dot = lambda x: x.replace(\" .\", \".\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleaner)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleaner)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleanString)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleanString)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(format_dot)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(format_dot)\n",
    "dataset = dataset.rename(columns={\"abstract_text\": \"summary\",\n",
    "                        \"article_text\": \"text\"})\n",
    "\n",
    "subset = dataset.iloc[3:5, :]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = []\n",
    "all_reduced_embs = []\n",
    "all_tokens = []\n",
    "all_clabels = []\n",
    "for indiv in subset[\"text\"].to_list():\n",
    "    o, l = tokenizeCorpus(indiv)\n",
    "    v = vectorizeCorpus(o, method=\"concat_l4\")\n",
    "    v, l = cleanAll(v, l)\n",
    "    reduced_v, clabels = clusterizeCorpus(UMAP(n_components=2, init=\"random\", random_state=0), v, \n",
    "                                        HDBSCAN())\n",
    "    tf_values = tf(l)\n",
    "    clusters_tf_values = clusters_tf(tf_values, l, clabels)\n",
    "    all_embs.append(v)\n",
    "    all_reduced_embs.append(reduced_v)\n",
    "    all_tokens.append(l)\n",
    "    all_clabels.append(clabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_tokens(tokens, clabels, embs):\n",
    "    d = {}\n",
    "    for token, clabel, emb in zip(tokens, clabels, embs):\n",
    "        if clabel in d.keys():\n",
    "            d[clabel][\"tokens\"].append(token)\n",
    "            d[clabel][\"embs\"].append(emb)\n",
    "        else:\n",
    "            d[clabel] = {\"tokens\": [token], \"embs\": [emb]}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tokens = tidy_tokens(all_tokens[1], all_clabels[1], all_reduced_embs[1])\n",
    "for k, v in d_tokens.items():\n",
    "    d_tokens[k][\"embs\"] = np.array(v[\"embs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(p, q):\n",
    "    p = np.array(p)\n",
    "    q = np.array(q)\n",
    "    return np.linalg.norm(p - q)\n",
    "\n",
    "\n",
    "def crossProduct(p, q, r):\n",
    "    pq = np.array(q) - np.array(p)\n",
    "    pr = np.array(r) - np.array(p)\n",
    "    return np.cross(pq, pr)\n",
    "\n",
    "\n",
    "def rotatingCaliper(points, convex_hull):\n",
    "   \n",
    "    # Takes O(n)\n",
    "    hull = [points[i] for i in range(len(points)) if i in convex_hull.vertices]\n",
    "    n = len(hull)\n",
    " \n",
    "    # Base Cases\n",
    "    if n == 1:\n",
    "        return 0\n",
    "    if n == 2:\n",
    "        return euclideanDistance(hull[0], hull[1])\n",
    "    k = 1\n",
    " \n",
    "    # Find the farthest vertex\n",
    "    # from hull[0] and hull[n-1]\n",
    "    while crossProduct(hull[n - 1], hull[0], hull[(k + 1) % n]) > crossProduct(hull[n - 1], hull[0], hull[k]):\n",
    "        k += 1\n",
    " \n",
    "    res = 0\n",
    " \n",
    "    # Check points from 0 to k\n",
    "    for i in range(k + 1):\n",
    "        j = (i + 1) % n\n",
    "        while crossProduct(hull[i], hull[(i + 1) % n], hull[(j + 1) % n]) > crossProduct(hull[i], hull[(i + 1) % n], hull[j]):\n",
    "            # Update res\n",
    "            res = max(res, euclideanDistance(hull[i], hull[(j + 1) % n]))\n",
    "            j = (j + 1) % n\n",
    " \n",
    "    # Return the result distance\n",
    "    return res\n",
    "\n",
    "def biggerDistance(points):\n",
    "    points = np.array(points)\n",
    "    convex_hull = ConvexHull(points)\n",
    "    return rotatingCaliper(points, convex_hull)\n",
    "\n",
    "# Code inspired by amit_mangal_ on geeksforgeeks forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_score(tokens_dict, clusters_tfs):\n",
    "    scores = {}\n",
    "    for k, v in tokens_dict.items():\n",
    "        try:\n",
    "            max_dist = biggerDistance(v[\"embs\"])\n",
    "            scores[k] = clusters_tfs[k]/(max_dist*len(v[\"tokens\"])) if max_dist > 0 else 0\n",
    "        except:\n",
    "            scores[k]=0\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tfs = clusters_tf(tf(all_tokens[1]), all_tokens[1], all_clabels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_score(d_tokens, c_tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in list(d_tokens.values())[:1]:\n",
    "    print(v[\"embs\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundancy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "c:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\.venv\\Lib\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "sys.path.append(r\"C:\\Pro\\Stages\\A4 - DVRC\\Work\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\myLibraries\")\n",
    "from MARScore.score import MARSCore\n",
    "from MARScore.utils import *\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>congenital adrenal hyperplasia ( cah ) refers ...</td>\n",
       "      <td>congenital adrenal hyperplasia is a group of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>type 1 diabetes ( t1d ) results from the destr...</td>\n",
       "      <td>objective(s):pentoxifylline is an immunomodula...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   \n",
       "3  congenital adrenal hyperplasia ( cah ) refers ...  \\\n",
       "4  type 1 diabetes ( t1d ) results from the destr...   \n",
       "\n",
       "                                             summary  \n",
       "3  congenital adrenal hyperplasia is a group of a...  \n",
       "4  objective(s):pentoxifylline is an immunomodula...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(r'C:\\Pro\\Stages\\A4 - DVRC\\Work\\Datasets\\pubmed\\test.json', lines=True)\n",
    "dataset = dataset[[\"article_text\", \"abstract_text\"]]\n",
    "cleaner = lambda x: \". \".join(x).replace(\"<S>\", \"\").strip()\n",
    "format_dot = lambda x: x.replace(\" .\", \".\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].replace(regex=r\"\\[[^\\]]*\\]\", value=\"\")\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleaner)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleaner)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(cleanString)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(cleanString)\n",
    "dataset.loc[:,\"abstract_text\"] = dataset[\"abstract_text\"].map(format_dot)\n",
    "dataset.loc[:,\"article_text\"] = dataset[\"article_text\"].map(format_dot)\n",
    "dataset = dataset.rename(columns={\"abstract_text\": \"summary\",\n",
    "                        \"article_text\": \"text\"})\n",
    "\n",
    "subset = dataset.iloc[3:5, :]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = []\n",
    "all_reduced_embs = []\n",
    "all_tokens = []\n",
    "all_clabels = []\n",
    "for indiv in subset[\"text\"].to_list():\n",
    "    o, l = tokenizeCorpus(indiv)\n",
    "    v = vectorizeCorpus(o, method=\"concat_l4\")\n",
    "    v, l = cleanAll(v, l)\n",
    "    reduced_v, clabels = clusterizeCorpus(UMAP(n_components=2, init=\"random\", random_state=0), v, \n",
    "                                        HDBSCAN())\n",
    "    tf_values = tf(l)\n",
    "    clusters_tf_values = clusters_tf(tf_values, l, clabels)\n",
    "    all_embs.append(v)\n",
    "    all_reduced_embs.append(reduced_v)\n",
    "    all_tokens.append(l)\n",
    "    all_clabels.append(clabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_per_cluster(tokens, clabels, embs):\n",
    "        \"\"\"\n",
    "        Groups embeddings and tokens by cluster.\n",
    "\n",
    "        :param1 tokens (list): List of text tokens associated with each embedding.\n",
    "        :param2 clabels (list): List of token's cluster index.\n",
    "        :param3 embs (list): List of embedding vectors for each token.\n",
    "\n",
    "        :output d (dict): Dictionnary containing embeddings and associated tokens for each cluster.\n",
    "        \"\"\"\n",
    "        d = {}\n",
    "        for token, clabel, emb in zip(tokens, clabels, embs):\n",
    "            if clabel in d.keys():\n",
    "                d[clabel][\"tokens\"].append(token)\n",
    "                d[clabel][\"embs\"].append(emb)\n",
    "            else:\n",
    "                d[clabel] = {\"tokens\": [token], \"embs\": [emb]}\n",
    "        for k, v in d.items():\n",
    "            d[k][\"embs\"] = np.array(v[\"embs\"])\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def redundancy_score(d_tokens):\n",
    "    \"\"\"\n",
    "    Evaluates redundancy in clusters. \n",
    "\n",
    "    :param1 d_tokens (dict): Dictionnary containing embeddings and associated tokens for each cluster.\n",
    "\n",
    "    :output (list): Redundancy matrix for a group of clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    def smallest_intercluster_distance(embs1, embs2):\n",
    "        \"\"\"\n",
    "        Determines the smallest inter-cluster distance between two clusters. \n",
    "\n",
    "        :param1 embs1 (list): List of embeddings for cluster 1.\n",
    "        :param2 embs2 (list): List of embeddings for cluster 2.\n",
    "\n",
    "        :output (float): Smallest inter-cluster distance.\n",
    "        \"\"\"\n",
    "        distance_matrix = []\n",
    "        for emb1 in embs1:\n",
    "            temp = []\n",
    "            for emb2 in embs2:\n",
    "                temp.append(np.linalg.norm(emb2 - emb1))\n",
    "            distance_matrix.append(temp)\n",
    "        distance_matrix = np.array(distance_matrix)\n",
    "        return distance_matrix.min()\n",
    "\n",
    "    try:\n",
    "        d_tokens.pop(-1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    k = sorted(d_tokens.keys())\n",
    "    l = len(k)\n",
    "    m = [[0 for j in range(l)] for i in range(l)]\n",
    "    for i in range(l):\n",
    "        for j in range(i, l):\n",
    "            m[i][j] = smallest_intercluster_distance(d_tokens[k[i]][\"embs\"], d_tokens[k[j]][\"embs\"])\n",
    "    m = np.triu(m)\n",
    "    m = m + m.T - np.diag(np.diag(m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tokens = tokens_per_cluster(all_tokens[0], all_clabels[0], all_embs[0])\n",
    "r_score = redundancy_score(d_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(r_score, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.308984989255926"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_score[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
