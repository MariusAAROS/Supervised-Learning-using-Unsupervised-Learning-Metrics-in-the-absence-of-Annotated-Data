{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = [\"Mon prenom est marius\"]\n",
    "can = [\"Je suis marius\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Token Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(model):\n",
    "    assert(type(model) == str)\n",
    "    if model == \"Word2Vec\":\n",
    "        wordvector_path = r'D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\GoogleNews-vectors-negative300.bin.gz'\n",
    "        emb = KeyedVectors.load_word2vec_format(wordvector_path, binary=True)\n",
    "    else:\n",
    "        print(\"Model not currently supported\")\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(corpus, model):\n",
    "    encoded_corpus = []\n",
    "    unknown = 0\n",
    "    for sentence in corpus:\n",
    "        encoded_sentence = []\n",
    "        for word in sentence.split(\" \"):\n",
    "            try:\n",
    "                encoded_sentence.append(model[word])\n",
    "            except:\n",
    "                unknown += 1\n",
    "        encoded_corpus.append(encoded_sentence)\n",
    "    return np.array(encoded_corpus, dtype=object), unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = model_load(\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#references, n_unknown_ref = encode([\"I am Marius\", \"I like trains\"], w2v)\n",
    "#candidates, n_unknown_cand = encode([\"My name is Marius\", \"I enjoy rail vehicules\"], w2v)\n",
    "\n",
    "references, n_unknown_ref = encode([\"I am Marius\"], w2v)\n",
    "candidates, n_unknown_cand = encode([\"My name is Marius\"], w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Reference :  (1, 3, 300) || Unknown Token Reference :  0\n",
      "Shape Candidate :  (1, 4, 300) || Unknown Token Candidate :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape Reference : \", references.shape, \"||\", \"Unknown Token Reference : \", n_unknown_ref)\n",
    "print(\"Shape Candidate : \", candidates.shape, \"||\", \"Unknown Token Candidate : \", n_unknown_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.519005613856723"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.transpose(references[0][0]), candidates[0][0])/(norm(references[0][0])*norm(candidates[0][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimilarityCandToRef(references, candidates):\n",
    "    proximity = lambda x, y: (np.matmul(np.transpose(x), y))/(norm(x)*norm(y))\n",
    "\n",
    "    all_proximities = []\n",
    "\n",
    "    for candidate, reference in zip(candidates, references):\n",
    "        proximities = []\n",
    "        for c_word in candidate:\n",
    "            sub_proximities = []\n",
    "            for r_word in reference:\n",
    "                sub_proximities.append(proximity(r_word, c_word))\n",
    "            proximities.append(sub_proximities)\n",
    "        all_proximities.append(proximities)\n",
    "    return all_proximities\n",
    "\n",
    "def SimilarityRefToCand(references, candidates):\n",
    "    proximity = lambda x, y: (np.matmul(np.transpose(x), y))/(norm(x)*norm(y))\n",
    "\n",
    "    all_proximities = []\n",
    "\n",
    "    for candidate, reference in zip(candidates, references):\n",
    "        proximities = []\n",
    "        for r_word in reference:\n",
    "            sub_proximities = []\n",
    "            for c_word in candidate:\n",
    "                sub_proximities.append(proximity(r_word, c_word))\n",
    "            proximities.append(sub_proximities)\n",
    "        all_proximities.append(proximities)\n",
    "    return all_proximities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "candToRef = SimilarityCandToRef(references, candidates)\n",
    "refToCand = SimilarityRefToCand(references, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.519005613856723, 0.18616442214576517, 0.04520518544899319],\n",
       "  [0.09242192671658575, 0.012498354833030686, 0.025547976598766665],\n",
       "  [0.2098326692090991, 0.3489852938028225, -0.00109822157119661],\n",
       "  [0.0368609406903856, 0.020396980932637056, 1.0]]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candToRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.519005613856723,\n",
       "   0.09242192671658575,\n",
       "   0.2098326692090991,\n",
       "   0.0368609406903856],\n",
       "  [0.18616442214576517,\n",
       "   0.012498354833030686,\n",
       "   0.3489852938028225,\n",
       "   0.020396980932637056],\n",
       "  [0.04520518544899319, 0.025547976598766665, -0.00109822157119661, 1.0]]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refToCand"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of P, R and F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### R calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullSum = []\n",
    "for individualSimilarity in candToRef:\n",
    "    currentSum = 0\n",
    "    for row in individualSimilarity:\n",
    "        currentSum += row[np.argmax(row)]\n",
    "    fullSum.append(currentSum)\n",
    "R = []\n",
    "for sum, reference in zip(fullSum, references):\n",
    "    R.append((1/norm(reference))*sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42425704559238325]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullSum = []\n",
    "for individualSimilarity in refToCand:\n",
    "    currentSum = 0\n",
    "    for row in individualSimilarity:\n",
    "        currentSum += row[np.argmax(row)]\n",
    "    fullSum.append(currentSum)\n",
    "P = []\n",
    "for sum, candidate in zip(fullSum, candidates):\n",
    "    P.append((1/norm(candidate))*sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3604158590807159]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOLD ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "new_references = []\n",
    "new_candidates = []\n",
    "\n",
    "for reference, candidate in zip(references, candidates):\n",
    "    size_diff = len(reference) - len(candidate)\n",
    "    if size_diff >= 0:\n",
    "        candidate = np.pad(candidate, (0, size_diff))\n",
    "        reference = np.array(reference)\n",
    "    else:\n",
    "        reference = np.pad(reference, [(0, np.abs(size_diff)), (0, 0)], mode=\"constant\")\n",
    "        candidate = np.array(candidate)\n",
    "    new_references.append(reference)\n",
    "    new_candidates.append(candidate)\n",
    "   \n",
    "\n",
    "references = np.array(new_references, dtype=object)\n",
    "candidates = np.array(new_candidates, dtype=object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
