{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = [\"Mon prenom est marius\"]\n",
    "can = [\"Je suis marius\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Token Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(model):\n",
    "    assert(type(model) == str)\n",
    "    if model == \"Word2Vec\":\n",
    "        wordvector_path = r'D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\GoogleNews-vectors-negative300.bin.gz'\n",
    "        emb = KeyedVectors.load_word2vec_format(wordvector_path, binary=True)\n",
    "    if model == \"Glove\":\n",
    "        glove_path = r'D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\glove2word2vec.txt'\n",
    "        emb = KeyedVectors.load_word2vec_format(glove_path)\n",
    "    else:\n",
    "        print(\"Model not currently supported\")\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(corpus, model):\n",
    "    encoded_corpus = []\n",
    "    unknown = 0\n",
    "    for sentence in corpus:\n",
    "        encoded_sentence = []\n",
    "        for word in sentence.split(\" \"):\n",
    "            try:\n",
    "                encoded_sentence.append(model[word])\n",
    "            except:\n",
    "                unknown += 1\n",
    "        encoded_corpus.append(encoded_sentence)\n",
    "    return np.array(encoded_corpus, dtype=object), unknown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = model_load(\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#references, n_unknown_ref = encode([\"I am Marius\", \"I like trains\"], w2v)\n",
    "#candidates, n_unknown_cand = encode([\"My name is Marius\", \"I enjoy rail vehicules\"], w2v)\n",
    "\n",
    "references, n_unknown_ref = encode([\"I am Marius\"], w2v)\n",
    "candidates, n_unknown_cand = encode([\"My name is Marius\"], w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Reference :  (1, 3, 300) || Unknown Token Reference :  0\n",
      "Shape Candidate :  (1, 4, 300) || Unknown Token Candidate :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape Reference : \", references.shape, \"||\", \"Unknown Token Reference : \", n_unknown_ref)\n",
    "print(\"Shape Candidate : \", candidates.shape, \"||\", \"Unknown Token Candidate : \", n_unknown_cand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "from gensim.test.utils import datapath, get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = load_facebook_vectors(r'D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_path = datapath(\"crime-and-punishment.bin\")\n",
    "wv = load_facebook_vectors(cap_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Glove"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversition to word2vec format (Do not compile unless necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = r\"D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\glove.6B\\glove.6B.300d.txt\"\n",
    "glove_temp = KeyedVectors.load_word2vec_format(glove_path, no_header=True)\n",
    "glove_temp.save_word2vec_format(r\"D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\glove2word2vec.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of formated glove file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalGlove = KeyedVectors.load_word2vec_format(r\"D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\glove2word2vec.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimilarityCandToRef(references, candidates):\n",
    "    proximity = lambda x, y: (np.matmul(np.transpose(x), y))/(norm(x)*norm(y))\n",
    "\n",
    "    all_proximities = []\n",
    "\n",
    "    for candidate, reference in zip(candidates, references):\n",
    "        proximities = []\n",
    "        for c_word in candidate:\n",
    "            sub_proximities = []\n",
    "            for r_word in reference:\n",
    "                sub_proximities.append(proximity(r_word, c_word))\n",
    "            proximities.append(sub_proximities)\n",
    "        all_proximities.append(proximities)\n",
    "    return all_proximities\n",
    "\n",
    "def SimilarityRefToCand(references, candidates):\n",
    "    proximity = lambda x, y: (np.matmul(np.transpose(x), y))/(norm(x)*norm(y))\n",
    "\n",
    "    all_proximities = []\n",
    "\n",
    "    for candidate, reference in zip(candidates, references):\n",
    "        proximities = []\n",
    "        for r_word in reference:\n",
    "            sub_proximities = []\n",
    "            for c_word in candidate:\n",
    "                sub_proximities.append(proximity(r_word, c_word))\n",
    "            proximities.append(sub_proximities)\n",
    "        all_proximities.append(proximities)\n",
    "    return all_proximities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "candToRef = SimilarityCandToRef(references, candidates)\n",
    "refToCand = SimilarityRefToCand(references, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.519005613856723, 0.18616442214576517, 0.04520518544899319],\n",
       "  [0.09242192671658575, 0.012498354833030686, 0.025547976598766665],\n",
       "  [0.2098326692090991, 0.3489852938028225, -0.00109822157119661],\n",
       "  [0.0368609406903856, 0.020396980932637056, 1.0]]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candToRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.519005613856723,\n",
       "   0.09242192671658575,\n",
       "   0.2098326692090991,\n",
       "   0.0368609406903856],\n",
       "  [0.18616442214576517,\n",
       "   0.012498354833030686,\n",
       "   0.3489852938028225,\n",
       "   0.020396980932637056],\n",
       "  [0.04520518544899319, 0.025547976598766665, -0.00109822157119661, 1.0]]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refToCand"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Calculation of P, R and F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### R calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullSum = []\n",
    "for individualSimilarity in candToRef:\n",
    "    currentSum = 0\n",
    "    for row in individualSimilarity:\n",
    "        currentSum += row[np.argmax(row)]\n",
    "    fullSum.append(currentSum)\n",
    "R = []\n",
    "for sum, reference in zip(fullSum, references):\n",
    "    R.append((1/norm(reference))*sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42425704559238325]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullSum = []\n",
    "for individualSimilarity in refToCand:\n",
    "    currentSum = 0\n",
    "    for row in individualSimilarity:\n",
    "        currentSum += row[np.argmax(row)]\n",
    "    fullSum.append(currentSum)\n",
    "P = []\n",
    "for sum, candidate in zip(fullSum, candidates):\n",
    "    P.append((1/norm(candidate))*sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3604158590807159]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = []\n",
    "\n",
    "for r, p in zip(R, P):\n",
    "    f = 2*((p*r)/(p+r))\n",
    "    F.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38973938477441966]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(candToRef, refToCand):\n",
    "    # R computation\n",
    "    fullSum = []\n",
    "    for individualSimilarity in candToRef:\n",
    "        currentSum = 0\n",
    "        for row in individualSimilarity:\n",
    "            currentSum += row[np.argmax(row)]\n",
    "        fullSum.append(currentSum)\n",
    "    R = []\n",
    "    for sum, reference in zip(fullSum, references):\n",
    "        R.append((1/norm(reference))*sum)\n",
    "\n",
    "    # P computation\n",
    "    fullSum = []\n",
    "    for individualSimilarity in refToCand:\n",
    "        currentSum = 0\n",
    "        for row in individualSimilarity:\n",
    "            currentSum += row[np.argmax(row)]\n",
    "        fullSum.append(currentSum)\n",
    "    P = []\n",
    "    for sum, candidate in zip(fullSum, candidates):\n",
    "        P.append((1/norm(candidate))*sum)\n",
    "    \n",
    "    # F computation\n",
    "    F = []\n",
    "    for r, p in zip(R, P):\n",
    "        f = 2*((p*r)/(p+r))\n",
    "        F.append(f)\n",
    "    \n",
    "    return (R, R, F)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Basic Test of the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_score.score import score\n",
    "from custom_score.utils import model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = model_load(\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.40998854847735094], [0.22880340017752968], [0.2937005518713847])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.03954665010154433], [0.05171590963278553], [0.04481993467824077])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(finalGlove)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOLDALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "new_references = []\n",
    "new_candidates = []\n",
    "\n",
    "for reference, candidate in zip(references, candidates):\n",
    "    size_diff = len(reference) - len(candidate)\n",
    "    if size_diff >= 0:\n",
    "        candidate = np.pad(candidate, (0, size_diff))\n",
    "        reference = np.array(reference)\n",
    "    else:\n",
    "        reference = np.pad(reference, [(0, np.abs(size_diff)), (0, 0)], mode=\"constant\")\n",
    "        candidate = np.array(candidate)\n",
    "    new_references.append(reference)\n",
    "    new_candidates.append(candidate)\n",
    "   \n",
    "\n",
    "references = np.array(new_references, dtype=object)\n",
    "candidates = np.array(new_candidates, dtype=object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
