{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\orteg\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\orteg\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\orteg\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\Users\\orteg\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from datetime import datetime\n",
    "import bert_score\n",
    "from custom_score.score import score, DynamicEmbeddingSampleTest, StaticEmbeddingSampleTest \n",
    "from custom_score.utils import model_load, encode\n",
    "import pickle\n",
    "#import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Custom BERTScore Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = [\"Mon prenom est marius\"]\n",
    "can = [\"Je suis marius\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Token Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(model):\n",
    "    assert(type(model) == str)\n",
    "    if model == \"Word2Vec\":\n",
    "        wordvector_path = r'D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\GoogleNews-vectors-negative300.bin.gz'\n",
    "        emb = KeyedVectors.load_word2vec_format(wordvector_path, binary=True)\n",
    "    if model == \"Glove\":\n",
    "        glove_path = r'D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\glove2word2vec.txt'\n",
    "        emb = KeyedVectors.load_word2vec_format(glove_path)\n",
    "    else:\n",
    "        print(\"Model not currently supported\")\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(corpus, model):\n",
    "    encoded_corpus = []\n",
    "    unknown = 0\n",
    "    for sentence in corpus:\n",
    "        encoded_sentence = []\n",
    "        for word in sentence.split(\" \"):\n",
    "            try:\n",
    "                encoded_sentence.append(model[word])\n",
    "            except:\n",
    "                unknown += 1\n",
    "        encoded_corpus.append(encoded_sentence)\n",
    "    return np.array(encoded_corpus, dtype=object), unknown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = model_load(\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#references, n_unknown_ref = encode([\"I am Marius\", \"I like trains\"], w2v)\n",
    "#candidates, n_unknown_cand = encode([\"My name is Marius\", \"I enjoy rail vehicules\"], w2v)\n",
    "\n",
    "references, n_unknown_ref = encode([\"I am Marius\"], w2v)\n",
    "candidates, n_unknown_cand = encode([\"My name is Marius\"], w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Reference :  (1, 3, 300) || Unknown Token Reference :  0\n",
      "Shape Candidate :  (1, 4, 300) || Unknown Token Candidate :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape Reference : \", references.shape, \"||\", \"Unknown Token Reference : \", n_unknown_ref)\n",
    "print(\"Shape Candidate : \", candidates.shape, \"||\", \"Unknown Token Candidate : \", n_unknown_cand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fasttext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversition to word2vec format (Do not compile unless necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.load_model(r'D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\wiki.en\\wiki.en.bin')\n",
    "kv = KeyedVectors(vector_size=ft_model.get_dimension())\n",
    "all_words = ft_model.get_words()\n",
    "all_vectors = [ft_model.get_word_vector(w) for w in all_words]\n",
    "kv.add_vectors(all_words, all_vectors)\n",
    "kv.save_word2vec_format('ftwords.txt', binary=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of formated fasttext file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = KeyedVectors.load_word2vec_format(r'D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\ftwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = KeyedVectors.load_word2vec_format(r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75779974,  0.5959443 , -0.27542254,  0.24059881, -0.5490175 ,\n",
       "        0.8300641 , -0.41410735,  0.7523287 ,  0.50460875, -0.86938876],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext[\"house\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Glove"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversition to word2vec format (Do not compile unless necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = r\"D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\glove.6B\\glove.6B.300d.txt\"\n",
    "glove_temp = KeyedVectors.load_word2vec_format(glove_path, no_header=True)\n",
    "glove_temp.save_word2vec_format(r\"D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\glove2word2vec.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of formated glove file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load_word2vec_format(r\"D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\glove2word2vec.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimilarityCandToRef(references, candidates):\n",
    "    proximity = lambda x, y: (np.matmul(np.transpose(x), y))/(norm(x)*norm(y))\n",
    "\n",
    "    all_proximities = []\n",
    "\n",
    "    for candidate, reference in zip(candidates, references):\n",
    "        proximities = []\n",
    "        for c_word in candidate:\n",
    "            sub_proximities = []\n",
    "            for r_word in reference:\n",
    "                sub_proximities.append(proximity(r_word, c_word))\n",
    "            proximities.append(sub_proximities)\n",
    "        all_proximities.append(proximities)\n",
    "    return all_proximities\n",
    "\n",
    "def SimilarityRefToCand(references, candidates):\n",
    "    proximity = lambda x, y: (np.matmul(np.transpose(x), y))/(norm(x)*norm(y))\n",
    "\n",
    "    all_proximities = []\n",
    "\n",
    "    for candidate, reference in zip(candidates, references):\n",
    "        proximities = []\n",
    "        for r_word in reference:\n",
    "            sub_proximities = []\n",
    "            for c_word in candidate:\n",
    "                sub_proximities.append(proximity(r_word, c_word))\n",
    "            proximities.append(sub_proximities)\n",
    "        all_proximities.append(proximities)\n",
    "    return all_proximities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'references' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m candToRef \u001b[39m=\u001b[39m SimilarityCandToRef(references, candidates)\n\u001b[0;32m      2\u001b[0m refToCand \u001b[39m=\u001b[39m SimilarityRefToCand(references, candidates)\n\u001b[0;32m      3\u001b[0m refToCand2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(candToRef) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'references' is not defined"
     ]
    }
   ],
   "source": [
    "candToRef = SimilarityCandToRef(references, candidates)\n",
    "refToCand = SimilarityRefToCand(references, candidates)\n",
    "refToCand2 = np.transpose(candToRef) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.519005613856723, 0.18616442214576517, 0.04520518544899319],\n",
       "  [0.09242192671658575, 0.012498354833030686, 0.025547976598766665],\n",
       "  [0.2098326692090991, 0.3489852938028225, -0.00109822157119661],\n",
       "  [0.0368609406903856, 0.020396980932637056, 1.0]]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candToRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.519005613856723,\n",
       "   0.09242192671658575,\n",
       "   0.2098326692090991,\n",
       "   0.0368609406903856],\n",
       "  [0.18616442214576517,\n",
       "   0.012498354833030686,\n",
       "   0.3489852938028225,\n",
       "   0.020396980932637056],\n",
       "  [0.04520518544899319, 0.025547976598766665, -0.00109822157119661, 1.0]]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refToCand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.51900561],\n",
       "        [ 0.09242193],\n",
       "        [ 0.20983267],\n",
       "        [ 0.03686094]],\n",
       "\n",
       "       [[ 0.18616442],\n",
       "        [ 0.01249835],\n",
       "        [ 0.34898529],\n",
       "        [ 0.02039698]],\n",
       "\n",
       "       [[ 0.04520519],\n",
       "        [ 0.02554798],\n",
       "        [-0.00109822],\n",
       "        [ 1.        ]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refToCand2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Calculation of P, R and F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### R calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullSum = []\n",
    "for individualSimilarity in candToRef:\n",
    "    currentSum = 0\n",
    "    for row in individualSimilarity:\n",
    "        currentSum += row[np.argmax(row)]\n",
    "    fullSum.append(currentSum)\n",
    "R = []\n",
    "for sum, reference in zip(fullSum, references):\n",
    "    R.append((1/norm(reference))*sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42425704559238325]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullSum = []\n",
    "for individualSimilarity in refToCand:\n",
    "    currentSum = 0\n",
    "    for row in individualSimilarity:\n",
    "        currentSum += row[np.argmax(row)]\n",
    "    fullSum.append(currentSum)\n",
    "P = []\n",
    "for sum, candidate in zip(fullSum, candidates):\n",
    "    P.append((1/norm(candidate))*sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3604158590807159]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = []\n",
    "\n",
    "for r, p in zip(R, P):\n",
    "    f = 2*((p*r)/(p+r))\n",
    "    F.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38973938477441966]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(candToRef, refToCand):\n",
    "    # R computation\n",
    "    fullSum = []\n",
    "    for individualSimilarity in candToRef:\n",
    "        currentSum = 0\n",
    "        for row in individualSimilarity:\n",
    "            currentSum += row[np.argmax(row)]\n",
    "        fullSum.append(currentSum)\n",
    "    R = []\n",
    "    for sum, reference in zip(fullSum, references):\n",
    "        R.append((1/norm(reference))*sum)\n",
    "\n",
    "    # P computation\n",
    "    fullSum = []\n",
    "    for individualSimilarity in refToCand:\n",
    "        currentSum = 0\n",
    "        for row in individualSimilarity:\n",
    "            currentSum += row[np.argmax(row)]\n",
    "        fullSum.append(currentSum)\n",
    "    P = []\n",
    "    for sum, candidate in zip(fullSum, candidates):\n",
    "        P.append((1/norm(candidate))*sum)\n",
    "    \n",
    "    # F computation\n",
    "    F = []\n",
    "    for r, p in zip(R, P):\n",
    "        f = 2*((p*r)/(p+r))\n",
    "        F.append(f)\n",
    "    \n",
    "    return (R, R, F)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - IDF Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_score.utils import computeIdf\n",
    "from custom_score.utils import getIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfDict = computeIdf(ref[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getIdf(idfDict, \"coucou\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Simplify Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function creation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanString(string, maxSpacing=10):\n",
    "    \"\"\"\n",
    "    :param1 string (string): Initial corpus\n",
    "    :param2 maxSpacing (int): Maximal number of adjacent space to be found and suppressed in the corpus.\n",
    "\n",
    "    :output clean (string): Cleansed corpus\n",
    "    \"\"\"\n",
    "\n",
    "    clean = string[:]\n",
    "\n",
    "    #remove linebreaks  \n",
    "    clean = clean.replace(\"\\n\", \" \")\n",
    "    clean = clean.replace(\"-\", \"\")\n",
    "\n",
    "    #remove surplus spacing\n",
    "    spacing = \"\".join([\" \" for _ in range(maxSpacing)])\n",
    "    for _ in range(maxSpacing-1):\n",
    "        spacing = spacing[:-1]\n",
    "        clean = clean.replace(spacing, \" \")\n",
    "    \n",
    "    return clean\n",
    "\n",
    "def sentenceSelection(corpus, scores, reductionFactor=2):\n",
    "    \"\"\"\n",
    "    Returns a list of selected indices of sentence that will constituate the new corpus.\n",
    "\n",
    "    :param1 corpus (list): List of sentences of the reference document.\n",
    "    :param2 scores (list): List of the similarity scores of each sentence of the reference compared to the entire reference document.\n",
    "    :param3 reductionFactor (float or int): Number determining how much the reference text will be shortened. \n",
    "\n",
    "    :output selected_indexes (list): List of indexes of the initial corpus sentences that have been selected.\n",
    "    \"\"\"\n",
    "    totalLength = len(corpus)\n",
    "    targetLength = int(totalLength/reductionFactor)\n",
    "    selected_indexes = []\n",
    "    \n",
    "    randomized_scores = [np.mean([curScore, uniform(0, 1)]) for curScore in scores]\n",
    "    ranking = np.argsort(randomized_scores)[::-1]\n",
    "    selected_indexes = ranking[:targetLength]\n",
    "\n",
    "    return selected_indexes\n",
    "\n",
    "def simplify(reference, model, reductionFactor=2, maxSpacing=10):\n",
    "    \"\"\"\n",
    "    Return a reduced string computed using static embedding vectors similarity. Also denoises the data by removing superfluous elements such as \"\\n\" or useless signs.\n",
    " \n",
    "    :param1 reference (string): Document to simplify.\n",
    "    :param2 model (dict): Dictionnary of keyed-vectors.\n",
    "    :param3 reductionFactor (float or int): Number determining how much the reference text will be shortened. \n",
    "    :param4 maxSpacing (int): Maximal number of adjacent space to be found and suppressed in the corpus.\n",
    "\n",
    "    :output simplified (string): Simplified version of the initial document.\n",
    "    \"\"\"\n",
    "\n",
    "    #preprocess corpus\n",
    "    clean = cleanString(reference, maxSpacing)\n",
    "    sentences = clean.split(\".\")\n",
    "    sentences.pop()\n",
    "    respaced_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if sentence[0] == \" \":\n",
    "            sentence = sentence[1:]\n",
    "        respaced_sentences.append(sentence)\n",
    "    \n",
    "    corpus = \" \".join(respaced_sentences)\n",
    "    scores = []\n",
    "    for sentence in respaced_sentences:\n",
    "        (R, _, _) = score(model, [sentence], [corpus])\n",
    "        scores.append(R[0])\n",
    "\n",
    "    indices = sentenceSelection(respaced_sentences, scores, reductionFactor)\n",
    "    \n",
    "    simplified = []\n",
    "    for index in indices:\n",
    "        simplified.append(respaced_sentences[index])\n",
    "    \n",
    "    simplified = \" \".join(simplified)\n",
    "\n",
    "    return simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Je suis marius. J'aime les fruits.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = model_load(\"Word2Vec\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'aime les fruits\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplify(test, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum0 = \"SECTION 1. SHORT TITLE.\\n\\n    This Act may be cited as the ``National Science Education Tax \\nIncentive for Businesses Act of 2007''.\\n\\nSEC. 2. CREDITS FOR CERTAIN CONTRIBUTIONS BENEFITING SCIENCE, \\n              TECHNOLOGY, ENGINEERING, AND MATHEMATICS EDUCATION AT THE \\n              ELEMENTARY AND SECONDARY SCHOOL LEVEL.\\n\\n    (a) In General.--Subpart D of part IV of subchapter A of chapter 1 \\nof the Internal Revenue Code of 1986 (relating to business related \\ncredits) is amended by adding at the end the following new section:\\n\\n``SEC. 45O. CONTRIBUTIONS BENEFITING SCIENCE, TECHNOLOGY, ENGINEERING, \\n              AND MATHEMATICS EDUCATION AT THE ELEMENTARY AND SECONDARY \\n              SCHOOL LEVEL.\\n\\n    ``(a) In General.--For purposes of section 38, the elementary and \\nsecondary science, technology, engineering, and mathematics (STEM) \\ncontributions credit determined under this section for the taxable year \\nis an amount equal to 100 percent of the qualified STEM contributions \\nof the taxpayer for such taxable year.\\n    ``(b) Qualified STEM Contributions.--For purposes of this section, \\nthe term `qualified STEM contributions' means--\\n            ``(1) STEM school contributions,\\n            ``(2) STEM teacher externship expenses, and\\n            ``(3) STEM teacher training expenses.\\n    ``(c) STEM School Contributions.--For purposes of this section--\\n            ``(1) In general.--The term `STEM school contributions' \\n        means--\\n                    ``(A) STEM property contributions, and\\n                    ``(B) STEM service contributions.\\n            ``(2) STEM property contributions.--The term `STEM property \\n        contributions' means the amount which would (but for subsection \\n        (f)) be allowed as a deduction under section 170 for a \\n        charitable contribution of STEM inventory property if--\\n                    ``(A) the donee is an elementary or secondary \\n                school described in section 170(b)(1)(A)(ii),\\n                    ``(B) substantially all of the use of the property \\n                by the donee is within the United States or within the \\n                defense dependents' education system for educational \\n                purposes in any of the grades K-12 that are related to \\n                the purpose or function of the donee,\\n                    ``(C) the original use of the property begins with \\n                the donee,\\n                    ``(D) the property will fit productively into the \\n                donee's education plan,\\n                    ``(E) the property is not transferred by the donee \\n                in exchange for money, other property, or services, \\n                except for shipping, installation and transfer costs, \\n                and\\n                    ``(F) the donee's use and disposition of the \\n                property will be in accordance with the provisions of \\n                subparagraphs (B) and (E).\\n        The determination of the amount of deduction under section 170 \\n        for purposes of this paragraph shall be made as if the \\n        limitation under section 170(e)(3)(B) applied to all STEM \\n        inventory property.\\n            ``(3) STEM service contributions.--The term `STEM service \\n        contributions' means the amount paid or incurred during the \\n        taxable year for STEM services provided in the United States or \\n        in the defense dependents' education system for the exclusive \\n        benefit of students at an elementary or secondary school \\n        described in section 170(b)(1)(A)(ii) but only if--\\n                    ``(A) the taxpayer is engaged in the trade or \\n                business of providing such services on a commercial \\n                basis, and\\n                    ``(B) no charge is imposed for providing such \\n                services.\\n            ``(4) STEM inventory property.--The term `STEM inventory \\n        property' means, with respect to any contribution to a school, \\n        any property--\\n                    ``(A) which is described in paragraph (1) or (2) of \\n                section 1221(a) with respect to the donor, and\\n                    ``(B) which is determined by the school to be \\n                needed by the school in providing education in grades \\n                K-12 in the areas of science, technology, engineering, \\n                or mathematics.\\n            ``(5) STEM services.--The term `STEM services' means, with \\n        respect to any contribution to a school, any service determined \\n        by the school to be needed by the school in providing education \\n        in grades K-12 in the areas of science, technology, \\n        engineering, or mathematics, including teaching courses of \\n        instruction at such school in any such area.\\n            ``(6) Defense dependents' education system.--For purposes \\n        of this subsection, the term `defense dependents' education \\n        system' means the program established and operated under the \\n        Defense Dependents' Education Act of 1978 (20 U.S.C. 921 et \\n        seq.).\\n    ``(d) STEM Teacher Externship Expenses.--For purposes of this \\nsection--\\n            ``(1) In general.--The term `STEM teacher externship \\n        expenses' means any amount paid or incurred to carry out a STEM \\n        externship program of the taxpayer but only to the extent that \\n        such amount is attributable to the participation in such \\n        program of any eligible STEM teacher, including amounts paid to \\n        such a teacher as a stipend while participating in such \\n        program.\\n            ``(2) STEM externship program.--The term `STEM externship \\n        program' means any program--\\n                    ``(A) established by a taxpayer engaged in a trade \\n                or business within an area of science, technology, \\n                engineering, or mathematics, and\\n                    ``(B) under which eligible STEM teachers receive \\n                training to enhance their teaching skills in the areas \\n                of science, technology, engineering, or mathematics or \\n                otherwise improve their knowledge in such areas.\\n            ``(3) Eligible stem teacher.--The term `eligible STEM \\n        teacher' means any individual--\\n                    ``(A) who is a teacher in grades K-12 at an \\n                educational organization described in section \\n                170(b)(1)(A)(ii) which is located in the United States \\n                or which is located on a United States military base \\n                outside the United States, and\\n                    ``(B) whose teaching responsibilities at such \\n                school include, or are likely to include, any course in \\n                the areas of science, technology, engineering, or \\n                mathematics.\\n    ``(e) STEM Teacher Training Expenses.--The term `STEM teacher \\ntraining expenses' means any amount paid or incurred by a taxpayer \\nengaged in a trade or business within an area of science, technology, \\nengineering, or mathematics which is attributable to the participation \\nof any eligible STEM teacher in a regular training program provided to \\nemployees of the taxpayer which is determined by such teacher's school \\nas enhancing such teacher's teaching skills in the areas of science, \\ntechnology, engineering, or mathematics.\\n    ``(f) Denial of Double Benefit.--No deduction shall be allowed \\nunder this chapter for any amount allowed as a credit under this \\nsection.''.\\n    (b) Conforming Amendments.--\\n            (1) Section 38(b) of such Code is amended by striking \\n        ``plus'' at the end of paragraph (30), by striking the period \\n        at the end of paragraph (31), and inserting ``, plus'', and by \\n        adding at the end the following new paragraph:\\n            ``(32) the elementary and secondary science, technology, \\n        engineering, and mathematics (STEM) contributions credit \\n        determined under section 45O.''.\\n            (2) The table of sections for subpart D of part IV of \\n        subchapter A of chapter 1 of such Code is amended by adding at \\n        the end the following new item:\\n\\n``Sec. 45O. Contributions benefiting science, technology, engineering, \\n                            and mathematics education at the elementary \\n                            and secondary school level.''.\\n    (c) Effective Date.--The amendments made by this section shall \\napply to taxable years beginning after the date of the enactment of \\nthis Act.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The term `STEM inventory property' means, with respect to any contribution to a school, any property ``(A) which is described in paragraph (1) or (2) of section 1221(a) with respect to the donor, and ``(B) which is determined by the school to be needed by the school in providing education in grades K12 in the areas of science, technology, engineering, or mathematics The term `STEM externship program' means any program ``(A) established by a taxpayer engaged in a trade or business within an area of science, technology, engineering, or mathematics, and ``(B) under which eligible STEM teachers receive training to enhance their teaching skills in the areas of science, technology, engineering, or mathematics or otherwise improve their knowledge in such areas Contributions benefiting science, technology, engineering, and mathematics education at the elementary and secondary school level The determination of the amount of deduction under section 170 for purposes of this paragraph shall be made as if the limitation under section 170(e)(3)(B) applied to all STEM inventory property For purposes of section 38, the elementary and secondary science, technology, engineering, and mathematics (STEM) contributions credit determined under this section for the taxable year is an amount equal to 100 percent of the qualified STEM contributions of the taxpayer for such taxable year (2) The table of sections for subpart D of part IV of subchapter A of chapter 1 of such Code is amended by adding at the end the following new item: ``Sec Subpart D of part IV of subchapter A of chapter 1 of the Internal Revenue Code of 1986 (relating to business related credits) is amended by adding at the end the following new section: ``SEC The term `STEM teacher externship expenses' means any amount paid or incurred to carry out a STEM externship program of the taxpayer but only to the extent that such amount is attributable to the participation in such program of any eligible STEM teacher, including amounts paid to such a teacher as a stipend while participating in such program (1) Section 38(b) of such Code is amended by striking ``plus'' at the end of paragraph (30), by striking the period at the end of paragraph (31), and inserting ``, plus'', and by adding at the end the following new paragraph: ``(32) the elementary and secondary science, technology, engineering, and mathematics (STEM) contributions credit determined under section 45O This Act may be cited as the ``National Science Education Tax Incentive for Businesses Act of 2007'' No deduction shall be allowed under this chapter for any amount allowed as a credit under this section ``(d) STEM Teacher Externship Expenses For purposes of this section ``(1) In general\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = simplify(billsum0, w2v, reductionFactor=4, maxSpacing=15)\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Package testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_score.score import simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum0 = \"SECTION 1. SHORT TITLE.\\n\\n    This Act may be cited as the ``National Science Education Tax \\nIncentive for Businesses Act of 2007''.\\n\\nSEC. 2. CREDITS FOR CERTAIN CONTRIBUTIONS BENEFITING SCIENCE, \\n              TECHNOLOGY, ENGINEERING, AND MATHEMATICS EDUCATION AT THE \\n              ELEMENTARY AND SECONDARY SCHOOL LEVEL.\\n\\n    (a) In General.--Subpart D of part IV of subchapter A of chapter 1 \\nof the Internal Revenue Code of 1986 (relating to business related \\ncredits) is amended by adding at the end the following new section:\\n\\n``SEC. 45O. CONTRIBUTIONS BENEFITING SCIENCE, TECHNOLOGY, ENGINEERING, \\n              AND MATHEMATICS EDUCATION AT THE ELEMENTARY AND SECONDARY \\n              SCHOOL LEVEL.\\n\\n    ``(a) In General.--For purposes of section 38, the elementary and \\nsecondary science, technology, engineering, and mathematics (STEM) \\ncontributions credit determined under this section for the taxable year \\nis an amount equal to 100 percent of the qualified STEM contributions \\nof the taxpayer for such taxable year.\\n    ``(b) Qualified STEM Contributions.--For purposes of this section, \\nthe term `qualified STEM contributions' means--\\n            ``(1) STEM school contributions,\\n            ``(2) STEM teacher externship expenses, and\\n            ``(3) STEM teacher training expenses.\\n    ``(c) STEM School Contributions.--For purposes of this section--\\n            ``(1) In general.--The term `STEM school contributions' \\n        means--\\n                    ``(A) STEM property contributions, and\\n                    ``(B) STEM service contributions.\\n            ``(2) STEM property contributions.--The term `STEM property \\n        contributions' means the amount which would (but for subsection \\n        (f)) be allowed as a deduction under section 170 for a \\n        charitable contribution of STEM inventory property if--\\n                    ``(A) the donee is an elementary or secondary \\n                school described in section 170(b)(1)(A)(ii),\\n                    ``(B) substantially all of the use of the property \\n                by the donee is within the United States or within the \\n                defense dependents' education system for educational \\n                purposes in any of the grades K-12 that are related to \\n                the purpose or function of the donee,\\n                    ``(C) the original use of the property begins with \\n                the donee,\\n                    ``(D) the property will fit productively into the \\n                donee's education plan,\\n                    ``(E) the property is not transferred by the donee \\n                in exchange for money, other property, or services, \\n                except for shipping, installation and transfer costs, \\n                and\\n                    ``(F) the donee's use and disposition of the \\n                property will be in accordance with the provisions of \\n                subparagraphs (B) and (E).\\n        The determination of the amount of deduction under section 170 \\n        for purposes of this paragraph shall be made as if the \\n        limitation under section 170(e)(3)(B) applied to all STEM \\n        inventory property.\\n            ``(3) STEM service contributions.--The term `STEM service \\n        contributions' means the amount paid or incurred during the \\n        taxable year for STEM services provided in the United States or \\n        in the defense dependents' education system for the exclusive \\n        benefit of students at an elementary or secondary school \\n        described in section 170(b)(1)(A)(ii) but only if--\\n                    ``(A) the taxpayer is engaged in the trade or \\n                business of providing such services on a commercial \\n                basis, and\\n                    ``(B) no charge is imposed for providing such \\n                services.\\n            ``(4) STEM inventory property.--The term `STEM inventory \\n        property' means, with respect to any contribution to a school, \\n        any property--\\n                    ``(A) which is described in paragraph (1) or (2) of \\n                section 1221(a) with respect to the donor, and\\n                    ``(B) which is determined by the school to be \\n                needed by the school in providing education in grades \\n                K-12 in the areas of science, technology, engineering, \\n                or mathematics.\\n            ``(5) STEM services.--The term `STEM services' means, with \\n        respect to any contribution to a school, any service determined \\n        by the school to be needed by the school in providing education \\n        in grades K-12 in the areas of science, technology, \\n        engineering, or mathematics, including teaching courses of \\n        instruction at such school in any such area.\\n            ``(6) Defense dependents' education system.--For purposes \\n        of this subsection, the term `defense dependents' education \\n        system' means the program established and operated under the \\n        Defense Dependents' Education Act of 1978 (20 U.S.C. 921 et \\n        seq.).\\n    ``(d) STEM Teacher Externship Expenses.--For purposes of this \\nsection--\\n            ``(1) In general.--The term `STEM teacher externship \\n        expenses' means any amount paid or incurred to carry out a STEM \\n        externship program of the taxpayer but only to the extent that \\n        such amount is attributable to the participation in such \\n        program of any eligible STEM teacher, including amounts paid to \\n        such a teacher as a stipend while participating in such \\n        program.\\n            ``(2) STEM externship program.--The term `STEM externship \\n        program' means any program--\\n                    ``(A) established by a taxpayer engaged in a trade \\n                or business within an area of science, technology, \\n                engineering, or mathematics, and\\n                    ``(B) under which eligible STEM teachers receive \\n                training to enhance their teaching skills in the areas \\n                of science, technology, engineering, or mathematics or \\n                otherwise improve their knowledge in such areas.\\n            ``(3) Eligible stem teacher.--The term `eligible STEM \\n        teacher' means any individual--\\n                    ``(A) who is a teacher in grades K-12 at an \\n                educational organization described in section \\n                170(b)(1)(A)(ii) which is located in the United States \\n                or which is located on a United States military base \\n                outside the United States, and\\n                    ``(B) whose teaching responsibilities at such \\n                school include, or are likely to include, any course in \\n                the areas of science, technology, engineering, or \\n                mathematics.\\n    ``(e) STEM Teacher Training Expenses.--The term `STEM teacher \\ntraining expenses' means any amount paid or incurred by a taxpayer \\nengaged in a trade or business within an area of science, technology, \\nengineering, or mathematics which is attributable to the participation \\nof any eligible STEM teacher in a regular training program provided to \\nemployees of the taxpayer which is determined by such teacher's school \\nas enhancing such teacher's teaching skills in the areas of science, \\ntechnology, engineering, or mathematics.\\n    ``(f) Denial of Double Benefit.--No deduction shall be allowed \\nunder this chapter for any amount allowed as a credit under this \\nsection.''.\\n    (b) Conforming Amendments.--\\n            (1) Section 38(b) of such Code is amended by striking \\n        ``plus'' at the end of paragraph (30), by striking the period \\n        at the end of paragraph (31), and inserting ``, plus'', and by \\n        adding at the end the following new paragraph:\\n            ``(32) the elementary and secondary science, technology, \\n        engineering, and mathematics (STEM) contributions credit \\n        determined under section 45O.''.\\n            (2) The table of sections for subpart D of part IV of \\n        subchapter A of chapter 1 of such Code is amended by adding at \\n        the end the following new item:\\n\\n``Sec. 45O. Contributions benefiting science, technology, engineering, \\n                            and mathematics education at the elementary \\n                            and secondary school level.''.\\n    (c) Effective Date.--The amendments made by this section shall \\napply to taxable years beginning after the date of the enactment of \\nthis Act.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify(billsum0, w2v, 4, 15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Basic Test of the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_score.score import score\n",
    "from custom_score.utils import model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = model_load(\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5415885295887227], [0.6913107305461017], [0.6073585639177453])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.03954665010154433], [0.05171590963278553], [0.04481993467824077])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6951478044587418], [0.6913107305461019], [0.6932239578823217])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(w2v, withIdf=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Billsum Dataset Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DynamicEmbeddingSampleTest(data, limit=3, modelPath = None, model = None, nbLayers = 24):\n",
    "    nbIter = 1\n",
    "    scores = []\n",
    "    init_time = datetime.now()\n",
    "    for row in data.iterrows():\n",
    "        curCand = [row[1][2]]\n",
    "        curRef = row[1][1]\n",
    "        curCand = [\" \".join(row[1][2].split(\"\\n\"))]\n",
    "        curRef = [\" \".join(row[1][1].split(\"\\n\"))]\n",
    "        assert len(curCand) == len(curRef)\n",
    "        if modelPath != None:\n",
    "            (P, R, F), hashname = bert_score.score(curCand, curRef, lang=\"en\", \n",
    "                                        model_type=modelPath, \n",
    "                                        num_layers=nbLayers, return_hash=True)\n",
    "        elif model != None:\n",
    "            (P, R, F), hashname = bert_score.score(curCand, curRef, lang=\"en\", \n",
    "                                        model_type=model, \n",
    "                                        num_layers=nbLayers, return_hash=True)\n",
    "        else:\n",
    "            (P, R, F), hashname = bert_score.score(curCand, curRef, lang=\"en\", return_hash=True)\n",
    "        P = P[0].item()\n",
    "        R = R[0].item()\n",
    "        F = F[0].item()\n",
    "        scores.append((P, R, F))\n",
    "        if nbIter >= limit:\n",
    "            break\n",
    "        nbIter += 1\n",
    "    runtime = (datetime.now() - init_time).total_seconds()\n",
    "    return scores, runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StaticEmbeddingSampleTest(data, model, limit=3):\n",
    "    nbIter = 1\n",
    "    scores = []\n",
    "    init_time = datetime.now()\n",
    "    for row in data.iterrows():\n",
    "        curCand = [row[1][2]]\n",
    "        curRef = row[1][1]\n",
    "        curCand = [\" \".join(row[1][2].split(\"\\n\"))]\n",
    "        curRef = [\" \".join(row[1][1].split(\"\\n\"))]\n",
    "        assert len(curCand) == len(curRef)\n",
    "        \n",
    "        (P, R, F) = score(model, curCand, curRef)\n",
    "        P = P[0]\n",
    "        R = R[0]\n",
    "        F = F[0]\n",
    "        scores.append((P, R, F))\n",
    "\n",
    "        if nbIter >= limit:\n",
    "            break\n",
    "        nbIter += 1\n",
    "    runtime = (datetime.now() - init_time).total_seconds()\n",
    "    return scores, runtime\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Load Benchmarking Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsumPath = r\"D:\\COURS\\A4\\S8\\Stage\\Documents\\Datasets\\Summary Evaluation\\BillSum\\corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>National Science Education Tax Incentive for B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Small Business Expansion and Hiring Act of 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SECTION 1. RELEASE OF DOCUMENTS CAPTURED IN IR...</td>\n",
       "      <td>Requires the Director of National Intelligence...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   \n",
       "0  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...  \\\n",
       "1  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "2  SECTION 1. RELEASE OF DOCUMENTS CAPTURED IN IR...   \n",
       "\n",
       "                                             summary  \n",
       "0  National Science Education Tax Incentive for B...  \n",
       "1  Small Business Expansion and Hiring Act of 201...  \n",
       "2  Requires the Director of National Intelligence...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#billsum_train = pd.read_json(path_or_buf = billsumPath + r\"\\us_train_data_final_OFFICIAL.jsonl\", lines=True)\n",
    "billsum_test = pd.read_json(path_or_buf = billsumPath + r\"\\us_test_data_final_OFFICIAL.jsonl\", lines=True)\n",
    "billsum_test = billsum_test.loc[:, [\"text\", \"summary\"]]\n",
    "billsum_test.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Remotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = tfds.load('huggingface:billsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Local Innovation and Coastal Protection Act of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Gun Show Background Check Act of 2008 - Amends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Recycled Roads Act of 2003 - Directs the Secre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Prosthetic and Custom Orthotic Parity Act of 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Investing in Neighborhood-focused, Vital, Evid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   \n",
       "0  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...  \\\n",
       "1  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "2  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "3  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "4  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "\n",
       "                                             summary  \n",
       "0  Local Innovation and Coastal Protection Act of...  \n",
       "1  Gun Show Background Check Act of 2008 - Amends...  \n",
       "2  Recycled Roads Act of 2003 - Directs the Secre...  \n",
       "3  Prosthetic and Custom Orthotic Parity Act of 2...  \n",
       "4  Investing in Neighborhood-focused, Vital, Evid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum_test = tfds.as_dataframe(billsum[\"test\"])\n",
    "billsum_test = billsum_test.loc[:, [\"text\", \"summary\"]]\n",
    "billsum_test.text = billsum_test.text.str.decode(\"utf-8\")\n",
    "billsum_test.summary = billsum_test.summary.str.decode(\"utf-8\")\n",
    "billsum_test.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Test : RoBERTa Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_scores, bert_runtime = DynamicEmbeddingSampleTest(billsum_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Test : Word2Vec Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_w2v_serialized = r\"D:\\COURS\\A4\\S8 - ESILV\\Stage\\Work\\Models\\serialized_w2v.pkl\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### W2V Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = model_load(\"Word2Vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_w2v_serialized, 'wb') as f:\n",
    "    pickle.dump(w2v, f)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### W2V test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_w2v_serialized, 'rb') as f:\n",
    "    w2v = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_scores, word2vec_runtime = StaticEmbeddingSampleTest(billsum_test, w2v, 3, withIdf = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Test : Fasttext Implementation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Test : Glove Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load_word2vec_format(r\"D:\\COURS\\A4\\S8\\Stage\\Documents\\Supervised-Learning-using-Unsupervised-Learning-Metrics-in-the-absence-of-Annotated-Data\\custom_BERTScore\\glove2word2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_scores, glove_runtime = StaticEmbeddingSampleTest(billsum_test, glove)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Runtime Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Roberta-24-layers</th>\n",
       "      <td>38.338537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec</th>\n",
       "      <td>4.411479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove</th>\n",
       "      <td>4.890593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     runtime\n",
       "Roberta-24-layers  38.338537\n",
       "Word2Vec            4.411479\n",
       "Glove               4.890593"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtimeTable = [bert_runtime, word2vec_runtime, glove_runtime]\n",
    "runtimeDf = pd.DataFrame(runtimeTable, columns=[\"runtime\"], index=[\"Roberta-24-layers\", \"Word2Vec\", \"Glove\"])\n",
    "runtimeDf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quality Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bert_P</th>\n",
       "      <th>Bert_R</th>\n",
       "      <th>Bert_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.874369</td>\n",
       "      <td>0.704338</td>\n",
       "      <td>0.780197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.846002</td>\n",
       "      <td>0.728316</td>\n",
       "      <td>0.782760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.873844</td>\n",
       "      <td>0.702725</td>\n",
       "      <td>0.778998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Bert_P    Bert_R    Bert_F\n",
       "0  0.874369  0.704338  0.780197\n",
       "1  0.846002  0.728316  0.782760\n",
       "2  0.873844  0.702725  0.778998"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_scores_Df = pd.DataFrame(bert_scores, columns=[\"Bert_P\", \"Bert_R\", \"Bert_F\"])\n",
    "bert_scores_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W2V_P</th>\n",
       "      <th>W2V_R</th>\n",
       "      <th>W2V_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646725</td>\n",
       "      <td>0.902619</td>\n",
       "      <td>0.753539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.699015</td>\n",
       "      <td>0.941868</td>\n",
       "      <td>0.802470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652091</td>\n",
       "      <td>0.959232</td>\n",
       "      <td>0.776389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      W2V_P     W2V_R     W2V_F\n",
       "0  0.646725  0.902619  0.753539\n",
       "1  0.699015  0.941868  0.802470\n",
       "2  0.652091  0.959232  0.776389"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_scores_Df = pd.DataFrame(word2vec_scores, columns=[\"W2V_P\", \"W2V_R\", \"W2V_F\"])\n",
    "word2vec_scores_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W2V_P_IDF</th>\n",
       "      <th>W2V_R_IDF</th>\n",
       "      <th>W2V_F_IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.636382</td>\n",
       "      <td>0.907588</td>\n",
       "      <td>0.748166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.623577</td>\n",
       "      <td>0.943714</td>\n",
       "      <td>0.750950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.593763</td>\n",
       "      <td>0.958194</td>\n",
       "      <td>0.733191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   W2V_P_IDF  W2V_R_IDF  W2V_F_IDF\n",
       "0   0.636382   0.907588   0.748166\n",
       "1   0.623577   0.943714   0.750950\n",
       "2   0.593763   0.958194   0.733191"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_scores_Df = pd.DataFrame(word2vec_scores, columns=[\"W2V_P_IDF\", \"W2V_R_IDF\", \"W2V_F_IDF\"])\n",
    "word2vec_scores_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_id</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>sum_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110_hr37</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>National Science Education Tax Incentive for B...</td>\n",
       "      <td>To amend the Internal Revenue Code of 1986 to ...</td>\n",
       "      <td>8494</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112_hr2873</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Small Business Expansion and Hiring Act of 201...</td>\n",
       "      <td>To amend the Internal Revenue Code of 1986 to ...</td>\n",
       "      <td>6522</td>\n",
       "      <td>1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109_s2408</td>\n",
       "      <td>SECTION 1. RELEASE OF DOCUMENTS CAPTURED IN IR...</td>\n",
       "      <td>Requires the Director of National Intelligence...</td>\n",
       "      <td>A bill to require the Director of National Int...</td>\n",
       "      <td>6154</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108_s1899</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>National Cancer Act of 2003 - Amends the Publi...</td>\n",
       "      <td>A bill to improve data collection and dissemin...</td>\n",
       "      <td>19853</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107_s1531</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Military Call-up Relief Act - Amends the Inter...</td>\n",
       "      <td>A bill to amend the Internal Revenue Code of 1...</td>\n",
       "      <td>6273</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107_hr4541</td>\n",
       "      <td>SECTION 1. RELIQUIDATION OF CERTAIN ENTRIES PR...</td>\n",
       "      <td>Requires the Customs Service to reliquidate ce...</td>\n",
       "      <td>To provide for reliquidation of entries premat...</td>\n",
       "      <td>11691</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111_s1495</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Service Dogs for Veterans Act of 2009 - Direct...</td>\n",
       "      <td>A bill to require the Secretary of Veterans Af...</td>\n",
       "      <td>5328</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>111_s3885</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Race to the Top Act of 2010 - Directs the Secr...</td>\n",
       "      <td>A bill to provide incentives for States and lo...</td>\n",
       "      <td>16668</td>\n",
       "      <td>1525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>113_hr1796</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Troop Talent Act of 2013 - Directs the Secreta...</td>\n",
       "      <td>Troop Talent Act of 2013</td>\n",
       "      <td>15352</td>\n",
       "      <td>2151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>103_hr1987</td>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Taxpayer's Right to View Act of 1993 - Amends ...</td>\n",
       "      <td>Taxpayer's Right to View Act of 1993</td>\n",
       "      <td>5633</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bill_id                                               text   \n",
       "0    110_hr37  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...  \\\n",
       "1  112_hr2873  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "2   109_s2408  SECTION 1. RELEASE OF DOCUMENTS CAPTURED IN IR...   \n",
       "3   108_s1899  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "4   107_s1531  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "5  107_hr4541  SECTION 1. RELIQUIDATION OF CERTAIN ENTRIES PR...   \n",
       "6   111_s1495  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "7   111_s3885  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "8  113_hr1796  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "9  103_hr1987  SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "\n",
       "                                             summary   \n",
       "0  National Science Education Tax Incentive for B...  \\\n",
       "1  Small Business Expansion and Hiring Act of 201...   \n",
       "2  Requires the Director of National Intelligence...   \n",
       "3  National Cancer Act of 2003 - Amends the Publi...   \n",
       "4  Military Call-up Relief Act - Amends the Inter...   \n",
       "5  Requires the Customs Service to reliquidate ce...   \n",
       "6  Service Dogs for Veterans Act of 2009 - Direct...   \n",
       "7  Race to the Top Act of 2010 - Directs the Secr...   \n",
       "8  Troop Talent Act of 2013 - Directs the Secreta...   \n",
       "9  Taxpayer's Right to View Act of 1993 - Amends ...   \n",
       "\n",
       "                                               title  text_len  sum_len  \n",
       "0  To amend the Internal Revenue Code of 1986 to ...      8494      321  \n",
       "1  To amend the Internal Revenue Code of 1986 to ...      6522     1424  \n",
       "2  A bill to require the Director of National Int...      6154      463  \n",
       "3  A bill to improve data collection and dissemin...     19853     1400  \n",
       "4  A bill to amend the Internal Revenue Code of 1...      6273      278  \n",
       "5  To provide for reliquidation of entries premat...     11691      114  \n",
       "6  A bill to require the Secretary of Veterans Af...      5328      379  \n",
       "7  A bill to provide incentives for States and lo...     16668     1525  \n",
       "8                           Troop Talent Act of 2013     15352     2151  \n",
       "9               Taxpayer's Right to View Act of 1993      5633      894  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLV_P</th>\n",
       "      <th>GLV_R</th>\n",
       "      <th>GLV_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.193759</td>\n",
       "      <td>-0.170188</td>\n",
       "      <td>-2.798021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.496544</td>\n",
       "      <td>-0.422760</td>\n",
       "      <td>-1.178411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.309721</td>\n",
       "      <td>-0.217137</td>\n",
       "      <td>-1.452770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GLV_P     GLV_R     GLV_F\n",
       "0  0.193759 -0.170188 -2.798021\n",
       "1  1.496544 -0.422760 -1.178411\n",
       "2  0.309721 -0.217137 -1.452770"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_scores_Df = pd.DataFrame(glove_scores, columns=[\"GLV_P\", \"GLV_R\", \"GLV_F\"])\n",
    "glove_scores_Df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOLDALL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "new_references = []\n",
    "new_candidates = []\n",
    "\n",
    "for reference, candidate in zip(references, candidates):\n",
    "    size_diff = len(reference) - len(candidate)\n",
    "    if size_diff >= 0:\n",
    "        candidate = np.pad(candidate, (0, size_diff))\n",
    "        reference = np.array(reference)\n",
    "    else:\n",
    "        reference = np.pad(reference, [(0, np.abs(size_diff)), (0, 0)], mode=\"constant\")\n",
    "        candidate = np.array(candidate)\n",
    "    new_references.append(reference)\n",
    "    new_candidates.append(candidate)\n",
    "   \n",
    "\n",
    "references = np.array(new_references, dtype=object)\n",
    "candidates = np.array(new_candidates, dtype=object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicating billsum summary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = []\n",
    "for i in range(billsum_test.shape[0]):\n",
    "    tab.append( billsum_test.iloc[i][2] + billsum_test.iloc[i][2])\n",
    "billsum_test[\"summary\"] = tab    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoSimilarity(sentences):\n",
    "    \"\"\"\n",
    "    :param1 sentences (list): List of sentences of the reference corpus.\n",
    "\n",
    "    :output similarities (list): List of cosine similarities between each sentence and the \n",
    "    \"\"\"\n",
    "    proximity = lambda x, y: (np.matmul(np.transpose(x), y))/(norm(x)*norm(y))\n",
    "    all = \" \".join(sentences)\n",
    "    similarities = []\n",
    "    for sentence in sentences:\n",
    "        currentSimilarity = []\n",
    "        for word in sentence.split(\" \"):\n",
    "            similarities.append(proximity(sentences, sentence))\n",
    "    return similarities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legacy version : sentence ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceSelection(corpus, scores, reductionFactor=2):\n",
    "    \"\"\"\n",
    "    Returns a list of selected indices of sentence that will constituate the new corpus.\n",
    "\n",
    "    :param1 corpus (list): List of sentences of the reference document.\n",
    "    :param2 scores (list): List of the similarity scores of each sentence of the reference compared to the entire reference document.\n",
    "    :param3 reductionFactor (float or int): Number determining how much the reference text will be shortened. \n",
    "\n",
    "    :output selected_indexes (list): List of indexes of the initial corpus sentences that have been selected.\n",
    "    \"\"\"\n",
    "    totalLength = len(corpus)\n",
    "    targetLength = int(totalLength/reductionFactor)\n",
    "    selected_indexes = []\n",
    "    for _ in range(targetLength):\n",
    "        randomized_scores = [np.mean([curScore, uniform(0, 1)]) for curScore in scores]\n",
    "        ranking = np.argsort(randomized_scores)[::-1]\n",
    "        for index in ranking:\n",
    "            if not index in selected_indexes:\n",
    "                selected_indexes.append(index)\n",
    "                break\n",
    "    return selected_indexes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
